


<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Configuration &mdash; Akka Documentation</title>
    
    <link rel="stylesheet" href="../_static/style.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/prettify.css" type="text/css" />
    <link rel="stylesheet" href="../_static/base.css" type="text/css" />
    <link rel="stylesheet" href="../_static/docs.css" type="text/css" />
    <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600,700" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '2.4.11',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/toc.js"></script>
    <script type="text/javascript" src="../_static/prettify.js"></script>
    <script type="text/javascript" src="../_static/highlightCode.js"></script>
    <script type="text/javascript" src="../_static/effects.core.js"></script>
    <script type="text/javascript" src="../_static/effects.highlight.js"></script>
    <script type="text/javascript" src="../_static/scrollTo.js"></script>
    <script type="text/javascript" src="../_static/contentsFix.js"></script>
    <script type="text/javascript" src="../_static/ga.js"></script>
    <script type="text/javascript" src="../_static/warnOldDocs.js"></script>
    <script type="text/javascript" src="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="top" title="Akka Documentation" href="../index.html" />
    <link rel="up" title="General" href="index.html" />
    <link rel="next" title="Actors" href="../scala/index-actors.html" />
    <link rel="prev" title="Message Delivery Reliability" href="message-delivery-reliability.html" />


  </head>
  <body>
  <div class="navbar">
    <div class="navbar-inner">
      <div class="container">
        <div class="navbar-logo">
          <a href="http://akka.io"><img class="svg-logo" src="../_static/akka_full_color.svg" /></a>
        </div>
        <ul class="nav">
          <li><a href="http://akka.io/docs">Documentation</a></li>
          <li><a href="http://doc.akka.io/docs/akka/current/additional/faq.html">FAQ</a></li>
          <li><a href="http://akka.io/downloads">Download</a></li>
          <li><a href="http://groups.google.com/group/akka-user">Mailing List</a></li>
          <li><a href="http://github.com/akka/akka">Code</a></li>
          <li><a href="http://www.lightbend.com/how/subscription">Commercial Support</a></li>
        </ul>
      </div>
    </div>
  </div>
  <div class="main">
    <div class="container">
      <div class="page-title">Configuration</div>
      <div class="pdf-link"><a href="../AkkaScala.pdf" title="Akka Scala Documentation"><img src="../_static/pdf-scala-icon.png" style="height: 40px;" /></a></div>
      <div class="pdf-link"><a href="../AkkaJava.pdf" title="Akka Java Documentation"><img src="../_static/pdf-java-icon.png" style="height: 40px;" /></a></div>
    </div>
    <div class="main-container">
      <div class="container">
        <div class="row">
          <div class="span12">
            <ul class="breadcrumb">
              <li>
                 <span class="divider">|</span> <a href="../scala/index-actors.html">Actors</a> <span class="divider">»</span>
              </li>
              <li>
                <a href="../java.html">Java Contents</a> <span class="divider">|</span> <a href="../scala.html">Scala Contents</a>
              </li>
              <li>
                <span class="divider">«</span> <a href="message-delivery-reliability.html">Message Delivery Reliability</a> <span class="divider">|</span>
              </li>
              <li style="float: left">
                Version 2.4.11
              </li>
              <li style="float: left">
                <input type="search" id="search" class="form-control" />
              </li>
            </ul>
          </div>
        </div>
        <div class="row"><div class="span9">
            
  <div class="section" id="configuration">
<span id="id1"></span><h1>Configuration</h1>
<p>You can start using Akka without defining any configuration, since sensible default values
are provided. Later on you might need to amend the settings to change the default behavior
or adapt for specific runtime environments. Typical examples of settings that you
might amend:</p>
<ul class="simple">
<li>log level and logger backend</li>
<li>enable remoting</li>
<li>message serializers</li>
<li>definition of routers</li>
<li>tuning of dispatchers</li>
</ul>
<p>Akka uses the <a class="reference external" href="https://github.com/typesafehub/config">Typesafe Config Library</a>, which might also be a good choice
for the configuration of your own application or library built with or without
Akka. This library is implemented in Java with no external dependencies; you
should have a look at its documentation (in particular about <a class="reference external" href="http://typesafehub.github.io/config/v1.2.0/com/typesafe/config/ConfigFactory.html">ConfigFactory</a>),
which is only summarized in the following.</p>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">If you use Akka from the Scala REPL from the 2.9.x series,
and you do not provide your own ClassLoader to the ActorSystem,
start the REPL with &quot;-Yrepl-sync&quot; to work around a deficiency in
the REPLs provided Context ClassLoader.</p>
</div>
<div class="section" id="where-configuration-is-read-from">
<h2>Where configuration is read from</h2>
<p>All configuration for Akka is held within instances of <tt class="xref py py-class docutils literal"><span class="pre">ActorSystem</span></tt>, or
put differently, as viewed from the outside, <tt class="xref py py-class docutils literal"><span class="pre">ActorSystem</span></tt> is the only
consumer of configuration information. While constructing an actor system, you
can either pass in a <tt class="xref py py-class docutils literal"><span class="pre">Config</span></tt> object or not, where the second case is
equivalent to passing <tt class="docutils literal"><span class="pre">ConfigFactory.load()</span></tt> (with the right class loader).
This means roughly that the default is to parse all <tt class="docutils literal"><span class="pre">application.conf</span></tt>,
<tt class="docutils literal"><span class="pre">application.json</span></tt> and <tt class="docutils literal"><span class="pre">application.properties</span></tt> found at the root of the
class path—please refer to the aforementioned documentation for details. The
actor system then merges in all <tt class="docutils literal"><span class="pre">reference.conf</span></tt> resources found at the root
of the class path to form the fallback configuration, i.e. it internally uses</p>
<div class="highlight-scala"><div class="highlight"><pre><span class="n">appConfig</span><span class="o">.</span><span class="n">withFallback</span><span class="o">(</span><span class="nc">ConfigFactory</span><span class="o">.</span><span class="n">defaultReference</span><span class="o">(</span><span class="n">classLoader</span><span class="o">))</span>
</pre></div>
</div>
<p>The philosophy is that code never contains default values, but instead relies
upon their presence in the <tt class="docutils literal"><span class="pre">reference.conf</span></tt> supplied with the library in
question.</p>
<p>Highest precedence is given to overrides given as system properties, see <a class="reference external" href="https://github.com/typesafehub/config/blob/master/HOCON.md">the
HOCON specification</a> (near the
bottom). Also noteworthy is that the application configuration—which defaults
to <tt class="docutils literal"><span class="pre">application</span></tt>—may be overridden using the <tt class="docutils literal"><span class="pre">config.resource</span></tt> property
(there are more, please refer to the <a class="reference external" href="https://github.com/typesafehub/config/blob/master/README.md">Config docs</a>).</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">If you are writing an Akka application, keep you configuration in
<tt class="docutils literal"><span class="pre">application.conf</span></tt> at the root of the class path. If you are writing an
Akka-based library, keep its configuration in <tt class="docutils literal"><span class="pre">reference.conf</span></tt> at the root
of the JAR file.</p>
</div>
</div>
<div class="section" id="when-using-jarjar-onejar-assembly-or-any-jar-bundler">
<h2>When using JarJar, OneJar, Assembly or any jar-bundler</h2>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">Akka's configuration approach relies heavily on the notion of every
module/jar having its own reference.conf file, all of these will be
discovered by the configuration and loaded. Unfortunately this also means
that if you put/merge multiple jars into the same jar, you need to merge all the
reference.confs as well. Otherwise all defaults will be lost and Akka will not function.</p>
</div>
<p>If you are using Maven to package your application, you can also make use of
the <a class="reference external" href="http://maven.apache.org/plugins/maven-shade-plugin">Apache Maven Shade Plugin</a> support for <a class="reference external" href="http://maven.apache.org/plugins/maven-shade-plugin/examples/resource-transformers.html#AppendingTransformer">Resource
Transformers</a>
to merge all the reference.confs on the build classpath into one.</p>
<p>The plugin configuration might look like this:</p>
<div class="highlight-scala"><div class="highlight"><pre><span class="o">&lt;</span><span class="n">plugin</span><span class="o">&gt;</span>
 <span class="o">&lt;</span><span class="n">groupId</span><span class="o">&gt;</span><span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">maven</span><span class="o">.</span><span class="n">plugins</span><span class="o">&lt;/</span><span class="n">groupId</span><span class="o">&gt;</span>
 <span class="o">&lt;</span><span class="n">artifactId</span><span class="o">&gt;</span><span class="n">maven</span><span class="o">-</span><span class="n">shade</span><span class="o">-</span><span class="n">plugin</span><span class="o">&lt;/</span><span class="n">artifactId</span><span class="o">&gt;</span>
 <span class="o">&lt;</span><span class="n">version</span><span class="o">&gt;</span><span class="mf">1.5</span><span class="o">&lt;/</span><span class="n">version</span><span class="o">&gt;</span>
 <span class="o">&lt;</span><span class="n">executions</span><span class="o">&gt;</span>
  <span class="o">&lt;</span><span class="n">execution</span><span class="o">&gt;</span>
   <span class="o">&lt;</span><span class="n">phase</span><span class="o">&gt;</span><span class="n">package</span><span class="o">&lt;/</span><span class="n">phase</span><span class="o">&gt;</span>
   <span class="o">&lt;</span><span class="n">goals</span><span class="o">&gt;</span>
    <span class="o">&lt;</span><span class="n">goal</span><span class="o">&gt;</span><span class="n">shade</span><span class="o">&lt;/</span><span class="n">goal</span><span class="o">&gt;</span>
   <span class="o">&lt;/</span><span class="n">goals</span><span class="o">&gt;</span>
   <span class="o">&lt;</span><span class="n">configuration</span><span class="o">&gt;</span>
    <span class="o">&lt;</span><span class="n">shadedArtifactAttached</span><span class="o">&gt;</span><span class="kc">true</span><span class="o">&lt;/</span><span class="n">shadedArtifactAttached</span><span class="o">&gt;</span>
    <span class="o">&lt;</span><span class="n">shadedClassifierName</span><span class="o">&gt;</span><span class="n">allinone</span><span class="o">&lt;/</span><span class="n">shadedClassifierName</span><span class="o">&gt;</span>
    <span class="o">&lt;</span><span class="n">artifactSet</span><span class="o">&gt;</span>
     <span class="o">&lt;</span><span class="n">includes</span><span class="o">&gt;</span>
      <span class="o">&lt;</span><span class="n">include</span><span class="o">&gt;*:*&lt;/</span><span class="n">include</span><span class="o">&gt;</span>
     <span class="o">&lt;/</span><span class="n">includes</span><span class="o">&gt;</span>
    <span class="o">&lt;/</span><span class="n">artifactSet</span><span class="o">&gt;</span>
    <span class="o">&lt;</span><span class="n">transformers</span><span class="o">&gt;</span>
      <span class="o">&lt;</span><span class="n">transformer</span>
       <span class="n">implementation</span><span class="o">=</span><span class="s">&quot;org.apache.maven.plugins.shade.resource.AppendingTransformer&quot;</span><span class="o">&gt;</span>
       <span class="o">&lt;</span><span class="n">resource</span><span class="o">&gt;</span><span class="n">reference</span><span class="o">.</span><span class="n">conf</span><span class="o">&lt;/</span><span class="n">resource</span><span class="o">&gt;</span>
      <span class="o">&lt;/</span><span class="n">transformer</span><span class="o">&gt;</span>
      <span class="o">&lt;</span><span class="n">transformer</span>
       <span class="n">implementation</span><span class="o">=</span><span class="s">&quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer&quot;</span><span class="o">&gt;</span>
       <span class="o">&lt;</span><span class="n">manifestEntries</span><span class="o">&gt;</span>
        <span class="o">&lt;</span><span class="nc">Main</span><span class="o">-</span><span class="nc">Class</span><span class="o">&gt;</span><span class="n">akka</span><span class="o">.</span><span class="nc">Main</span><span class="o">&lt;/</span><span class="nc">Main</span><span class="o">-</span><span class="nc">Class</span><span class="o">&gt;</span>
       <span class="o">&lt;/</span><span class="n">manifestEntries</span><span class="o">&gt;</span>
      <span class="o">&lt;/</span><span class="n">transformer</span><span class="o">&gt;</span>
    <span class="o">&lt;/</span><span class="n">transformers</span><span class="o">&gt;</span>
   <span class="o">&lt;/</span><span class="n">configuration</span><span class="o">&gt;</span>
  <span class="o">&lt;/</span><span class="n">execution</span><span class="o">&gt;</span>
 <span class="o">&lt;/</span><span class="n">executions</span><span class="o">&gt;</span>
<span class="o">&lt;/</span><span class="n">plugin</span><span class="o">&gt;</span>
</pre></div>
</div>
</div>
<div class="section" id="custom-application-conf">
<h2>Custom application.conf</h2>
<p>A custom <tt class="docutils literal"><span class="pre">application.conf</span></tt> might look like this:</p>
<div class="highlight-scala"><pre># In this file you can override any option defined in the reference files.
# Copy in parts of the reference files and modify as you please.

akka {

  # Loggers to register at boot time (akka.event.Logging$DefaultLogger logs
  # to STDOUT)
  loggers = ["akka.event.slf4j.Slf4jLogger"]

  # Log level used by the configured loggers (see "loggers") as soon
  # as they have been started; before that, see "stdout-loglevel"
  # Options: OFF, ERROR, WARNING, INFO, DEBUG
  loglevel = "DEBUG"

  # Log level for the very basic logger activated during ActorSystem startup.
  # This logger prints the log messages to stdout (System.out).
  # Options: OFF, ERROR, WARNING, INFO, DEBUG
  stdout-loglevel = "DEBUG"

  # Filter of log events that is used by the LoggingAdapter before
  # publishing log events to the eventStream.
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

  actor {
    provider = "cluster"

    default-dispatcher {
      # Throughput for default Dispatcher, set to 1 for as fair as possible
      throughput = 10
    }
  }

  remote {
    # The port clients should connect to. Default is 2552.
    netty.tcp.port = 4711
  }
}</pre>
</div>
</div>
<div class="section" id="including-files">
<h2>Including files</h2>
<p>Sometimes it can be useful to include another configuration file, for example if you have one <tt class="docutils literal"><span class="pre">application.conf</span></tt> with all
environment independent settings and then override some settings for specific environments.</p>
<p>Specifying system property with <tt class="docutils literal"><span class="pre">-Dconfig.resource=/dev.conf</span></tt> will load the <tt class="docutils literal"><span class="pre">dev.conf</span></tt> file, which includes the <tt class="docutils literal"><span class="pre">application.conf</span></tt></p>
<p>dev.conf:</p>
<div class="highlight-scala"><div class="highlight"><pre><span class="n">include</span> <span class="s">&quot;application&quot;</span>

<span class="n">akka</span> <span class="o">{</span>
  <span class="n">loglevel</span> <span class="k">=</span> <span class="s">&quot;DEBUG&quot;</span>
<span class="o">}</span>
</pre></div>
</div>
<p>More advanced include and substitution mechanisms are explained in the <a class="reference external" href="https://github.com/typesafehub/config/blob/master/HOCON.md">HOCON</a>
specification.</p>
</div>
<div class="section" id="logging-of-configuration">
<span id="dakka-log-config-on-start"></span><h2>Logging of Configuration</h2>
<p>If the system or config property <tt class="docutils literal"><span class="pre">akka.log-config-on-start</span></tt> is set to <tt class="docutils literal"><span class="pre">on</span></tt>, then the
complete configuration is logged at INFO level when the actor system is started. This is
useful when you are uncertain of what configuration is used.</p>
<p>If in doubt, you can also easily and nicely inspect configuration objects
before or after using them to construct an actor system:</p>
<div class="highlight-scala"><pre>Welcome to Scala version 2.11.8 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0).
Type in expressions to have them evaluated.
Type :help for more information.

scala&gt; import com.typesafe.config._
import com.typesafe.config._

scala&gt; ConfigFactory.parseString("a.b=12")
res0: com.typesafe.config.Config = Config(SimpleConfigObject({"a" : {"b" : 12}}))

scala&gt; res0.root.render
res1: java.lang.String =
{
    # String: 1
    "a" : {
        # String: 1
        "b" : 12
    }
}</pre>
</div>
<p>The comments preceding every item give detailed information about the origin of
the setting (file &amp; line number) plus possible comments which were present,
e.g. in the reference configuration. The settings as merged with the reference
and parsed by the actor system can be displayed like this:</p>
<div class="highlight-java"><div class="highlight"><pre><span class="kd">final</span> <span class="n">ActorSystem</span> <span class="n">system</span> <span class="o">=</span> <span class="n">ActorSystem</span><span class="o">.</span><span class="na">create</span><span class="o">();</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">system</span><span class="o">.</span><span class="na">settings</span><span class="o">());</span>
<span class="c1">// this is a shortcut for system.settings().config().root().render()</span>
</pre></div>
</div>
</div>
<div class="section" id="a-word-about-classloaders">
<h2>A Word About ClassLoaders</h2>
<p>In several places of the configuration file it is possible to specify the
fully-qualified class name of something to be instantiated by Akka. This is
done using Java reflection, which in turn uses a <tt class="xref py py-class docutils literal"><span class="pre">ClassLoader</span></tt>. Getting
the right one in challenging environments like application containers or OSGi
bundles is not always trivial, the current approach of Akka is that each
<tt class="xref py py-class docutils literal"><span class="pre">ActorSystem</span></tt> implementation stores the current thread’s context class
loader (if available, otherwise just its own loader as in
<tt class="docutils literal"><span class="pre">this.getClass.getClassLoader</span></tt>) and uses that for all reflective accesses.
This implies that putting Akka on the boot class path will yield
<tt class="xref py py-class docutils literal"><span class="pre">NullPointerException</span></tt> from strange places: this is simply not
supported.</p>
</div>
<div class="section" id="application-specific-settings">
<h2>Application specific settings</h2>
<p>The configuration can also be used for application specific settings.
A good practice is to place those settings in an Extension, as described in:</p>
<blockquote>
<div><ul class="simple">
<li>Scala API: <a class="reference internal" href="../scala/extending-akka.html#extending-akka-scala-settings"><em>Application specific settings</em></a></li>
<li>Java API: <a class="reference internal" href="../java/extending-akka.html#extending-akka-java-settings"><em>Application specific settings</em></a></li>
</ul>
</div></blockquote>
</div>
<div class="section" id="configuring-multiple-actorsystem">
<h2>Configuring multiple ActorSystem</h2>
<p>If you have more than one <tt class="docutils literal"><span class="pre">ActorSystem</span></tt> (or you're writing a
library and have an <tt class="docutils literal"><span class="pre">ActorSystem</span></tt> that may be separate from the
application's) you may want to separate the configuration for each
system.</p>
<p>Given that <tt class="docutils literal"><span class="pre">ConfigFactory.load()</span></tt> merges all resources with matching name
from the whole class path, it is easiest to utilize that functionality and
differentiate actor systems within the hierarchy of the configuration:</p>
<div class="highlight-scala"><div class="highlight"><pre><span class="n">myapp1</span> <span class="o">{</span>
  <span class="n">akka</span><span class="o">.</span><span class="n">loglevel</span> <span class="k">=</span> <span class="s">&quot;WARNING&quot;</span>
  <span class="n">my</span><span class="o">.</span><span class="n">own</span><span class="o">.</span><span class="n">setting</span> <span class="k">=</span> <span class="mi">43</span>
<span class="o">}</span>
<span class="n">myapp2</span> <span class="o">{</span>
  <span class="n">akka</span><span class="o">.</span><span class="n">loglevel</span> <span class="k">=</span> <span class="s">&quot;ERROR&quot;</span>
  <span class="n">app2</span><span class="o">.</span><span class="n">setting</span> <span class="k">=</span> <span class="s">&quot;appname&quot;</span>
<span class="o">}</span>
<span class="n">my</span><span class="o">.</span><span class="n">own</span><span class="o">.</span><span class="n">setting</span> <span class="k">=</span> <span class="mi">42</span>
<span class="n">my</span><span class="o">.</span><span class="n">other</span><span class="o">.</span><span class="n">setting</span> <span class="k">=</span> <span class="s">&quot;hello&quot;</span>
</pre></div>
</div>
<div class="highlight-scala"><div class="highlight"><pre><span class="k">val</span> <span class="n">config</span> <span class="k">=</span> <span class="nc">ConfigFactory</span><span class="o">.</span><span class="n">load</span><span class="o">()</span>
<span class="k">val</span> <span class="n">app1</span> <span class="k">=</span> <span class="nc">ActorSystem</span><span class="o">(</span><span class="s">&quot;MyApp1&quot;</span><span class="o">,</span> <span class="n">config</span><span class="o">.</span><span class="n">getConfig</span><span class="o">(</span><span class="s">&quot;myapp1&quot;</span><span class="o">).</span><span class="n">withFallback</span><span class="o">(</span><span class="n">config</span><span class="o">))</span>
<span class="k">val</span> <span class="n">app2</span> <span class="k">=</span> <span class="nc">ActorSystem</span><span class="o">(</span><span class="s">&quot;MyApp2&quot;</span><span class="o">,</span>
  <span class="n">config</span><span class="o">.</span><span class="n">getConfig</span><span class="o">(</span><span class="s">&quot;myapp2&quot;</span><span class="o">).</span><span class="n">withOnlyPath</span><span class="o">(</span><span class="s">&quot;akka&quot;</span><span class="o">).</span><span class="n">withFallback</span><span class="o">(</span><span class="n">config</span><span class="o">))</span>
</pre></div>
</div>
<p>These two samples demonstrate different variations of the “lift-a-subtree”
trick: in the first case, the configuration accessible from within the actor
system is this</p>
<div class="highlight-ruby"><div class="highlight"><pre><span class="n">akka</span><span class="o">.</span><span class="n">loglevel</span> <span class="o">=</span> <span class="s2">&quot;WARNING&quot;</span>
<span class="n">my</span><span class="o">.</span><span class="n">own</span><span class="o">.</span><span class="n">setting</span> <span class="o">=</span> <span class="mi">43</span>
<span class="n">my</span><span class="o">.</span><span class="n">other</span><span class="o">.</span><span class="n">setting</span> <span class="o">=</span> <span class="s2">&quot;hello&quot;</span>
<span class="sr">//</span> <span class="n">plus</span> <span class="n">myapp1</span> <span class="ow">and</span> <span class="n">myapp2</span> <span class="n">subtrees</span>
</pre></div>
</div>
<p>while in the second one, only the “akka” subtree is lifted, with the following
result</p>
<div class="highlight-ruby"><div class="highlight"><pre><span class="n">akka</span><span class="o">.</span><span class="n">loglevel</span> <span class="o">=</span> <span class="s2">&quot;ERROR&quot;</span>
<span class="n">my</span><span class="o">.</span><span class="n">own</span><span class="o">.</span><span class="n">setting</span> <span class="o">=</span> <span class="mi">42</span>
<span class="n">my</span><span class="o">.</span><span class="n">other</span><span class="o">.</span><span class="n">setting</span> <span class="o">=</span> <span class="s2">&quot;hello&quot;</span>
<span class="sr">//</span> <span class="n">plus</span> <span class="n">myapp1</span> <span class="ow">and</span> <span class="n">myapp2</span> <span class="n">subtrees</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The configuration library is really powerful, explaining all features exceeds
the scope affordable here. In particular not covered are how to include other
configuration files within other files (see a small example at <a class="reference internal" href="#including-files">Including
files</a>) and copying parts of the configuration tree by way of path
substitutions.</p>
</div>
<p>You may also specify and parse the configuration programmatically in other ways when instantiating
the <tt class="docutils literal"><span class="pre">ActorSystem</span></tt>.</p>
<div class="highlight-scala"><div class="highlight"><pre><span class="k">import</span> <span class="nn">akka.actor.ActorSystem</span>
<span class="k">import</span> <span class="nn">com.typesafe.config.ConfigFactory</span>
    <span class="k">val</span> <span class="n">customConf</span> <span class="k">=</span> <span class="nc">ConfigFactory</span><span class="o">.</span><span class="n">parseString</span><span class="o">(</span><span class="s">&quot;&quot;&quot;</span>
<span class="s">      akka.actor.deployment {</span>
<span class="s">        /my-service {</span>
<span class="s">          router = round-robin-pool</span>
<span class="s">          nr-of-instances = 3</span>
<span class="s">        }</span>
<span class="s">      }</span>
<span class="s">      &quot;&quot;&quot;</span><span class="o">)</span>
    <span class="c1">// ConfigFactory.load sandwiches customConfig between default reference</span>
    <span class="c1">// config and default overrides, and then resolves it.</span>
    <span class="k">val</span> <span class="n">system</span> <span class="k">=</span> <span class="nc">ActorSystem</span><span class="o">(</span><span class="s">&quot;MySystem&quot;</span><span class="o">,</span> <span class="nc">ConfigFactory</span><span class="o">.</span><span class="n">load</span><span class="o">(</span><span class="n">customConf</span><span class="o">))</span>
</pre></div>
</div>
</div>
<div class="section" id="reading-configuration-from-a-custom-location">
<h2>Reading configuration from a custom location</h2>
<p>You can replace or supplement <tt class="docutils literal"><span class="pre">application.conf</span></tt> either in code
or using system properties.</p>
<p>If you're using <tt class="docutils literal"><span class="pre">ConfigFactory.load()</span></tt> (which Akka does by
default) you can replace <tt class="docutils literal"><span class="pre">application.conf</span></tt> by defining
<tt class="docutils literal"><span class="pre">-Dconfig.resource=whatever</span></tt>, <tt class="docutils literal"><span class="pre">-Dconfig.file=whatever</span></tt>, or
<tt class="docutils literal"><span class="pre">-Dconfig.url=whatever</span></tt>.</p>
<p>From inside your replacement file specified with
<tt class="docutils literal"><span class="pre">-Dconfig.resource</span></tt> and friends, you can <tt class="docutils literal"><span class="pre">include</span>
<span class="pre">&quot;application&quot;</span></tt> if you still want to use
<tt class="docutils literal"><span class="pre">application.{conf,json,properties}</span></tt> as well.  Settings
specified before <tt class="docutils literal"><span class="pre">include</span> <span class="pre">&quot;application&quot;</span></tt> would be overridden by
the included file, while those after would override the included
file.</p>
<p>In code, there are many customization options.</p>
<p>There are several overloads of <tt class="docutils literal"><span class="pre">ConfigFactory.load()</span></tt>; these
allow you to specify something to be sandwiched between system
properties (which override) and the defaults (from
<tt class="docutils literal"><span class="pre">reference.conf</span></tt>), replacing the usual
<tt class="docutils literal"><span class="pre">application.{conf,json,properties}</span></tt> and replacing
<tt class="docutils literal"><span class="pre">-Dconfig.file</span></tt> and friends.</p>
<p>The simplest variant of <tt class="docutils literal"><span class="pre">ConfigFactory.load()</span></tt> takes a resource
basename (instead of <tt class="docutils literal"><span class="pre">application</span></tt>); <tt class="docutils literal"><span class="pre">myname.conf</span></tt>,
<tt class="docutils literal"><span class="pre">myname.json</span></tt>, and <tt class="docutils literal"><span class="pre">myname.properties</span></tt> would then be used
instead of <tt class="docutils literal"><span class="pre">application.{conf,json,properties}</span></tt>.</p>
<p>The most flexible variant takes a <tt class="docutils literal"><span class="pre">Config</span></tt> object, which
you can load using any method in <tt class="docutils literal"><span class="pre">ConfigFactory</span></tt>.  For example
you could put a config string in code using
<tt class="docutils literal"><span class="pre">ConfigFactory.parseString()</span></tt> or you could make a map and
<tt class="docutils literal"><span class="pre">ConfigFactory.parseMap()</span></tt>, or you could load a file.</p>
<p>You can also combine your custom config with the usual config,
that might look like:</p>
<div class="highlight-scala"><div class="highlight"><pre><span class="c1">// make a Config with just your special setting</span>
<span class="nc">Config</span> <span class="n">myConfig</span> <span class="k">=</span>
  <span class="nc">ConfigFactory</span><span class="o">.</span><span class="n">parseString</span><span class="o">(</span><span class="s">&quot;something=somethingElse&quot;</span><span class="o">);</span>
<span class="c1">// load the normal config stack (system props,</span>
<span class="c1">// then application.conf, then reference.conf)</span>
<span class="nc">Config</span> <span class="n">regularConfig</span> <span class="k">=</span>
  <span class="nc">ConfigFactory</span><span class="o">.</span><span class="n">load</span><span class="o">();</span>
<span class="c1">// override regular stack with myConfig</span>
<span class="nc">Config</span> <span class="n">combined</span> <span class="k">=</span>
  <span class="n">myConfig</span><span class="o">.</span><span class="n">withFallback</span><span class="o">(</span><span class="n">regularConfig</span><span class="o">);</span>
<span class="c1">// put the result in between the overrides</span>
<span class="c1">// (system props) and defaults again</span>
<span class="nc">Config</span> <span class="n">complete</span> <span class="k">=</span>
  <span class="nc">ConfigFactory</span><span class="o">.</span><span class="n">load</span><span class="o">(</span><span class="n">combined</span><span class="o">);</span>
<span class="c1">// create ActorSystem</span>
<span class="nc">ActorSystem</span> <span class="n">system</span> <span class="k">=</span>
  <span class="nc">ActorSystem</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="s">&quot;myname&quot;</span><span class="o">,</span> <span class="n">complete</span><span class="o">);</span>
</pre></div>
</div>
<p>When working with <tt class="docutils literal"><span class="pre">Config</span></tt> objects, keep in mind that there are
three &quot;layers&quot; in the cake:</p>
<blockquote>
<div><ul class="simple">
<li><tt class="docutils literal"><span class="pre">ConfigFactory.defaultOverrides()</span></tt> (system properties)</li>
<li>the app's settings</li>
<li><tt class="docutils literal"><span class="pre">ConfigFactory.defaultReference()</span></tt> (reference.conf)</li>
</ul>
</div></blockquote>
<p>The normal goal is to customize the middle layer while leaving the
other two alone.</p>
<blockquote>
<div><ul class="simple">
<li><tt class="docutils literal"><span class="pre">ConfigFactory.load()</span></tt> loads the whole stack</li>
<li>the overloads of <tt class="docutils literal"><span class="pre">ConfigFactory.load()</span></tt> let you specify a
different middle layer</li>
<li>the <tt class="docutils literal"><span class="pre">ConfigFactory.parse()</span></tt> variations load single files or resources</li>
</ul>
</div></blockquote>
<p>To stack two layers, use <tt class="docutils literal"><span class="pre">override.withFallback(fallback)</span></tt>; try
to keep system props (<tt class="docutils literal"><span class="pre">defaultOverrides()</span></tt>) on top and
<tt class="docutils literal"><span class="pre">reference.conf</span></tt> (<tt class="docutils literal"><span class="pre">defaultReference()</span></tt>) on the bottom.</p>
<p>Do keep in mind, you can often just add another <tt class="docutils literal"><span class="pre">include</span></tt>
statement in <tt class="docutils literal"><span class="pre">application.conf</span></tt> rather than writing code.
Includes at the top of <tt class="docutils literal"><span class="pre">application.conf</span></tt> will be overridden by
the rest of <tt class="docutils literal"><span class="pre">application.conf</span></tt>, while those at the bottom will
override the earlier stuff.</p>
</div>
<div class="section" id="actor-deployment-configuration">
<h2>Actor Deployment Configuration</h2>
<p>Deployment settings for specific actors can be defined in the <tt class="docutils literal"><span class="pre">akka.actor.deployment</span></tt>
section of the configuration. In the deployment section it is possible to define
things like dispatcher, mailbox, router settings, and remote deployment.
Configuration of these features are described in the chapters detailing corresponding
topics. An example may look like this:</p>
<div class="highlight-scala"><pre>akka.actor.deployment {

  # '/user/actorA/actorB' is a remote deployed actor
  /actorA/actorB {
    remote = "akka.tcp://sampleActorSystem@127.0.0.1:2553"
  }
  
  # all direct children of '/user/actorC' have a dedicated dispatcher 
  "/actorC/*" {
    dispatcher = my-dispatcher
  }

  # all descendants of '/user/actorC' (direct children, and their children recursively)
  # have a dedicated dispatcher
  "/actorC/**" {
    dispatcher = my-dispatcher
  }
  
  # '/user/actorD/actorE' has a special priority mailbox
  /actorD/actorE {
    mailbox = prio-mailbox
  }
  
  # '/user/actorF/actorG/actorH' is a random pool
  /actorF/actorG/actorH {
    router = random-pool
    nr-of-instances = 5
  }
}

my-dispatcher {
  fork-join-executor.parallelism-min = 10
  fork-join-executor.parallelism-max = 10
}
prio-mailbox {
  mailbox-type = "a.b.MyPrioMailbox"
}
</pre>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The deployment section for a specific actor is identified by the
path of the actor relative to <tt class="docutils literal"><span class="pre">/user</span></tt>.</p>
</div>
<p>You can use asterisks as wildcard matches for the actor path sections, so you could specify:
<tt class="docutils literal"><span class="pre">/*/sampleActor</span></tt> and that would match all <tt class="docutils literal"><span class="pre">sampleActor</span></tt> on that level in the hierarchy.
In addition, please note:</p>
<blockquote>
<div><ul class="simple">
<li>you can also use wildcards in the last position to match all actors at a certain level: <tt class="docutils literal"><span class="pre">/someParent/*</span></tt></li>
<li>you can use double-wildcards in the last position to match all child actors and their children
recursively: <tt class="docutils literal"><span class="pre">/someParent/**</span></tt></li>
<li>non-wildcard matches always have higher priority to match than wildcards, and single wildcard matches
have higher priority than double-wildcards, so: <tt class="docutils literal"><span class="pre">/foo/bar</span></tt> is considered <strong>more specific</strong> than
<tt class="docutils literal"><span class="pre">/foo/*</span></tt>, which is considered <strong>more specific</strong> than <tt class="docutils literal"><span class="pre">/foo/**</span></tt>. Only the highest priority match is used</li>
<li>wildcards <strong>cannot</strong> be used to partially match section, like this: <tt class="docutils literal"><span class="pre">/foo*/bar</span></tt>, <tt class="docutils literal"><span class="pre">/f*o/bar</span></tt> etc.</li>
</ul>
</div></blockquote>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Double-wildcards can only be placed in the last position.</p>
</div>
</div>
<div class="section" id="listing-of-the-reference-configuration">
<h2>Listing of the Reference Configuration</h2>
<p>Each Akka module has a reference configuration file with the default values.</p>
<div class="section" id="akka-actor">
<span id="config-akka-actor"></span><h3>akka-actor</h3>
<div class="highlight-none"><div class="highlight"><pre>####################################
# Akka Actor Reference Config File #
####################################

# This is the reference config file that contains all the default settings.
# Make your edits/overrides in your application.conf.

# Akka version, checked against the runtime version of Akka. Loaded from generated conf file.
include &quot;version&quot;

akka {
  # Home directory of Akka, modules in the deploy directory will be loaded
  home = &quot;&quot;

  # Loggers to register at boot time (akka.event.Logging$DefaultLogger logs
  # to STDOUT)
  loggers = [&quot;akka.event.Logging$DefaultLogger&quot;]
  
  # Filter of log events that is used by the LoggingAdapter before 
  # publishing log events to the eventStream. It can perform
  # fine grained filtering based on the log source. The default
  # implementation filters on the `loglevel`.
  # FQCN of the LoggingFilter. The Class of the FQCN must implement 
  # akka.event.LoggingFilter and have a public constructor with
  # (akka.actor.ActorSystem.Settings, akka.event.EventStream) parameters.
  logging-filter = &quot;akka.event.DefaultLoggingFilter&quot;

  # Specifies the default loggers dispatcher
  loggers-dispatcher = &quot;akka.actor.default-dispatcher&quot;

  # Loggers are created and registered synchronously during ActorSystem
  # start-up, and since they are actors, this timeout is used to bound the
  # waiting time
  logger-startup-timeout = 5s

  # Log level used by the configured loggers (see &quot;loggers&quot;) as soon
  # as they have been started; before that, see &quot;stdout-loglevel&quot;
  # Options: OFF, ERROR, WARNING, INFO, DEBUG
  loglevel = &quot;INFO&quot;

  # Log level for the very basic logger activated during ActorSystem startup.
  # This logger prints the log messages to stdout (System.out).
  # Options: OFF, ERROR, WARNING, INFO, DEBUG
  stdout-loglevel = &quot;WARNING&quot;

  # Log the complete configuration at INFO level when the actor system is started.
  # This is useful when you are uncertain of what configuration is used.
  log-config-on-start = off

  # Log at info level when messages are sent to dead letters.
  # Possible values:
  # on: all dead letters are logged
  # off: no logging of dead letters
  # n: positive integer, number of dead letters that will be logged
  log-dead-letters = 10

  # Possibility to turn off logging of dead letters while the actor system
  # is shutting down. Logging is only done when enabled by &#39;log-dead-letters&#39;
  # setting.
  log-dead-letters-during-shutdown = on

  # List FQCN of extensions which shall be loaded at actor system startup.
  # Library extensions are regular extensions that are loaded at startup and are
  # available for third party library authors to enable auto-loading of extensions when
  # present on the classpath. This is done by appending entries:
  # &#39;library-extensions += &quot;Extension&quot;&#39; in the library `reference.conf`.
  #
  # Should not be set by end user applications in &#39;application.conf&#39;, use the extensions property for that
  #
  library-extensions = ${?akka.library-extensions} []

  # List FQCN of extensions which shall be loaded at actor system startup.
  # Should be on the format: &#39;extensions = [&quot;foo&quot;, &quot;bar&quot;]&#39; etc.
  # See the Akka Documentation for more info about Extensions
  extensions = []

  # Toggles whether threads created by this ActorSystem should be daemons or not
  daemonic = off

  # JVM shutdown, System.exit(-1), in case of a fatal error,
  # such as OutOfMemoryError
  jvm-exit-on-fatal-error = on

  actor {

    # Either one of &quot;local&quot;, &quot;remote&quot; or &quot;cluster&quot; or the
    # FQCN of the ActorRefProvider to be used; the below is the built-in default,
    # note that &quot;remote&quot; and &quot;cluster&quot; requires the akka-remote and akka-cluster
    # artifacts to be on the classpath.
    provider = &quot;local&quot;

    # The guardian &quot;/user&quot; will use this class to obtain its supervisorStrategy.
    # It needs to be a subclass of akka.actor.SupervisorStrategyConfigurator.
    # In addition to the default there is akka.actor.StoppingSupervisorStrategy.
    guardian-supervisor-strategy = &quot;akka.actor.DefaultSupervisorStrategy&quot;

    # Timeout for ActorSystem.actorOf
    creation-timeout = 20s

    # Serializes and deserializes (non-primitive) messages to ensure immutability,
    # this is only intended for testing.
    serialize-messages = off

    # Serializes and deserializes creators (in Props) to ensure that they can be
    # sent over the network, this is only intended for testing. Purely local deployments
    # as marked with deploy.scope == LocalScope are exempt from verification.
    serialize-creators = off

    # Timeout for send operations to top-level actors which are in the process
    # of being started. This is only relevant if using a bounded mailbox or the
    # CallingThreadDispatcher for a top-level actor.
    unstarted-push-timeout = 10s

    typed {
      # Default timeout for typed actor methods with non-void return type
      timeout = 5s
    }
    
    # Mapping between ´deployment.router&#39; short names to fully qualified class names
    router.type-mapping {
      from-code = &quot;akka.routing.NoRouter&quot;
      round-robin-pool = &quot;akka.routing.RoundRobinPool&quot;
      round-robin-group = &quot;akka.routing.RoundRobinGroup&quot;
      random-pool = &quot;akka.routing.RandomPool&quot;
      random-group = &quot;akka.routing.RandomGroup&quot;
      balancing-pool = &quot;akka.routing.BalancingPool&quot;
      smallest-mailbox-pool = &quot;akka.routing.SmallestMailboxPool&quot;
      broadcast-pool = &quot;akka.routing.BroadcastPool&quot;
      broadcast-group = &quot;akka.routing.BroadcastGroup&quot;
      scatter-gather-pool = &quot;akka.routing.ScatterGatherFirstCompletedPool&quot;
      scatter-gather-group = &quot;akka.routing.ScatterGatherFirstCompletedGroup&quot;
      tail-chopping-pool = &quot;akka.routing.TailChoppingPool&quot;
      tail-chopping-group = &quot;akka.routing.TailChoppingGroup&quot;
      consistent-hashing-pool = &quot;akka.routing.ConsistentHashingPool&quot;
      consistent-hashing-group = &quot;akka.routing.ConsistentHashingGroup&quot;
    }

    deployment {

      # deployment id pattern - on the format: /parent/child etc.
      default {
      
        # The id of the dispatcher to use for this actor.
        # If undefined or empty the dispatcher specified in code
        # (Props.withDispatcher) is used, or default-dispatcher if not
        # specified at all.
        dispatcher = &quot;&quot;

        # The id of the mailbox to use for this actor.
        # If undefined or empty the default mailbox of the configured dispatcher
        # is used or if there is no mailbox configuration the mailbox specified
        # in code (Props.withMailbox) is used.
        # If there is a mailbox defined in the configured dispatcher then that
        # overrides this setting.
        mailbox = &quot;&quot;

        # routing (load-balance) scheme to use
        # - available: &quot;from-code&quot;, &quot;round-robin&quot;, &quot;random&quot;, &quot;smallest-mailbox&quot;,
        #              &quot;scatter-gather&quot;, &quot;broadcast&quot;
        # - or:        Fully qualified class name of the router class.
        #              The class must extend akka.routing.CustomRouterConfig and
        #              have a public constructor with com.typesafe.config.Config
        #              and optional akka.actor.DynamicAccess parameter.
        # - default is &quot;from-code&quot;;
        # Whether or not an actor is transformed to a Router is decided in code
        # only (Props.withRouter). The type of router can be overridden in the
        # configuration; specifying &quot;from-code&quot; means that the values specified
        # in the code shall be used.
        # In case of routing, the actors to be routed to can be specified
        # in several ways:
        # - nr-of-instances: will create that many children
        # - routees.paths: will route messages to these paths using ActorSelection,
        #   i.e. will not create children
        # - resizer: dynamically resizable number of routees as specified in
        #   resizer below
        router = &quot;from-code&quot;

        # number of children to create in case of a router;
        # this setting is ignored if routees.paths is given
        nr-of-instances = 1

        # within is the timeout used for routers containing future calls
        within = 5 seconds

        # number of virtual nodes per node for consistent-hashing router
        virtual-nodes-factor = 10

        tail-chopping-router {
          # interval is duration between sending message to next routee
          interval = 10 milliseconds
        }

        routees {
          # Alternatively to giving nr-of-instances you can specify the full
          # paths of those actors which should be routed to. This setting takes
          # precedence over nr-of-instances
          paths = []
        }
        
        # To use a dedicated dispatcher for the routees of the pool you can
        # define the dispatcher configuration inline with the property name 
        # &#39;pool-dispatcher&#39; in the deployment section of the router.
        # For example:
        # pool-dispatcher {
        #   fork-join-executor.parallelism-min = 5
        #   fork-join-executor.parallelism-max = 5
        # }

        # Routers with dynamically resizable number of routees; this feature is
        # enabled by including (parts of) this section in the deployment
        resizer {
        
          enabled = off

          # The fewest number of routees the router should ever have.
          lower-bound = 1

          # The most number of routees the router should ever have.
          # Must be greater than or equal to lower-bound.
          upper-bound = 10

          # Threshold used to evaluate if a routee is considered to be busy
          # (under pressure). Implementation depends on this value (default is 1).
          # 0:   number of routees currently processing a message.
          # 1:   number of routees currently processing a message has
          #      some messages in mailbox.
          # &gt; 1: number of routees with at least the configured pressure-threshold
          #      messages in their mailbox. Note that estimating mailbox size of
          #      default UnboundedMailbox is O(N) operation.
          pressure-threshold = 1

          # Percentage to increase capacity whenever all routees are busy.
          # For example, 0.2 would increase 20% (rounded up), i.e. if current
          # capacity is 6 it will request an increase of 2 more routees.
          rampup-rate = 0.2

          # Minimum fraction of busy routees before backing off.
          # For example, if this is 0.3, then we&#39;ll remove some routees only when
          # less than 30% of routees are busy, i.e. if current capacity is 10 and
          # 3 are busy then the capacity is unchanged, but if 2 or less are busy
          # the capacity is decreased.
          # Use 0.0 or negative to avoid removal of routees.
          backoff-threshold = 0.3

          # Fraction of routees to be removed when the resizer reaches the
          # backoffThreshold.
          # For example, 0.1 would decrease 10% (rounded up), i.e. if current
          # capacity is 9 it will request an decrease of 1 routee.
          backoff-rate = 0.1

          # Number of messages between resize operation.
          # Use 1 to resize before each message.
          messages-per-resize = 10
        }

        # Routers with dynamically resizable number of routees based on
        # performance metrics.
        # This feature is enabled by including (parts of) this section in
        # the deployment, cannot be enabled together with default resizer.
        optimal-size-exploring-resizer {

          enabled = off

          # The fewest number of routees the router should ever have.
          lower-bound = 1

          # The most number of routees the router should ever have.
          # Must be greater than or equal to lower-bound.
          upper-bound = 10

          # probability of doing a ramping down when all routees are busy
          # during exploration.
          chance-of-ramping-down-when-full = 0.2

          # Interval between each resize attempt
          action-interval = 5s

          # If the routees have not been fully utilized (i.e. all routees busy)
          # for such length, the resizer will downsize the pool.
          downsize-after-underutilized-for = 72h

          # Duration exploration, the ratio between the largest step size and
          # current pool size. E.g. if the current pool size is 50, and the
          # explore-step-size is 0.1, the maximum pool size change during
          # exploration will be +- 5
          explore-step-size = 0.1

          # Probabily of doing an exploration v.s. optmization.
          chance-of-exploration = 0.4

          # When downsizing after a long streak of underutilization, the resizer
          # will downsize the pool to the highest utiliziation multiplied by a
          # a downsize rasio. This downsize ratio determines the new pools size
          # in comparison to the highest utilization.
          # E.g. if the highest utilization is 10, and the down size ratio
          # is 0.8, the pool will be downsized to 8
          downsize-ratio = 0.8

          # When optimizing, the resizer only considers the sizes adjacent to the
          # current size. This number indicates how many adjacent sizes to consider.
          optimization-range = 16

          # The weight of the latest metric over old metrics when collecting
          # performance metrics.
          # E.g. if the last processing speed is 10 millis per message at pool
          # size 5, and if the new processing speed collected is 6 millis per
          # message at pool size 5. Given a weight of 0.3, the metrics
          # representing pool size 5 will be 6 * 0.3 + 10 * 0.7, i.e. 8.8 millis
          # Obviously, this number should be between 0 and 1.
          weight-of-latest-metric = 0.5
        }
      }

      /IO-DNS/inet-address {
        mailbox = &quot;unbounded&quot;
        router = &quot;consistent-hashing-pool&quot;
        nr-of-instances = 4
      }
    }

    default-dispatcher {
      # Must be one of the following
      # Dispatcher, PinnedDispatcher, or a FQCN to a class inheriting
      # MessageDispatcherConfigurator with a public constructor with
      # both com.typesafe.config.Config parameter and
      # akka.dispatch.DispatcherPrerequisites parameters.
      # PinnedDispatcher must be used together with executor=thread-pool-executor.
      type = &quot;Dispatcher&quot;

      # Which kind of ExecutorService to use for this dispatcher
      # Valid options:
      #  - &quot;default-executor&quot; requires a &quot;default-executor&quot; section
      #  - &quot;fork-join-executor&quot; requires a &quot;fork-join-executor&quot; section
      #  - &quot;thread-pool-executor&quot; requires a &quot;thread-pool-executor&quot; section
      #  - A FQCN of a class extending ExecutorServiceConfigurator
      executor = &quot;default-executor&quot;

      # This will be used if you have set &quot;executor = &quot;default-executor&quot;&quot;.
      # If an ActorSystem is created with a given ExecutionContext, this
      # ExecutionContext will be used as the default executor for all
      # dispatchers in the ActorSystem configured with
      # executor = &quot;default-executor&quot;. Note that &quot;default-executor&quot;
      # is the default value for executor, and therefore used if not
      # specified otherwise. If no ExecutionContext is given,
      # the executor configured in &quot;fallback&quot; will be used.
      default-executor {
        fallback = &quot;fork-join-executor&quot;
      }

      # This will be used if you have set &quot;executor = &quot;fork-join-executor&quot;&quot;
      # Underlying thread pool implementation is scala.concurrent.forkjoin.ForkJoinPool
      fork-join-executor {
        # Min number of threads to cap factor-based parallelism number to
        parallelism-min = 8

        # The parallelism factor is used to determine thread pool size using the
        # following formula: ceil(available processors * factor). Resulting size
        # is then bounded by the parallelism-min and parallelism-max values.
        parallelism-factor = 3.0

        # Max number of threads to cap factor-based parallelism number to
        parallelism-max = 64

        # Setting to &quot;FIFO&quot; to use queue like peeking mode which &quot;poll&quot; or &quot;LIFO&quot; to use stack
        # like peeking mode which &quot;pop&quot;.
        task-peeking-mode = &quot;FIFO&quot;
      }

      # This will be used if you have set &quot;executor = &quot;thread-pool-executor&quot;&quot;
      # Underlying thread pool implementation is java.util.concurrent.ThreadPoolExecutor
      thread-pool-executor {
        # Keep alive time for threads
        keep-alive-time = 60s
        
        # Define a fixed thread pool size with this property. The corePoolSize
        # and the maximumPoolSize of the ThreadPoolExecutor will be set to this
        # value, if it is defined. Then the other pool-size properties will not
        # be used. 
        # 
        # Valid values are: `off` or a positive integer.
        fixed-pool-size = off

        # Min number of threads to cap factor-based corePoolSize number to
        core-pool-size-min = 8

        # The core-pool-size-factor is used to determine corePoolSize of the 
        # ThreadPoolExecutor using the following formula: 
        # ceil(available processors * factor).
        # Resulting size is then bounded by the core-pool-size-min and
        # core-pool-size-max values.
        core-pool-size-factor = 3.0

        # Max number of threads to cap factor-based corePoolSize number to
        core-pool-size-max = 64

        # Minimum number of threads to cap factor-based maximumPoolSize number to
        max-pool-size-min = 8

        # The max-pool-size-factor is used to determine maximumPoolSize of the 
        # ThreadPoolExecutor using the following formula:
        # ceil(available processors * factor)
        # The maximumPoolSize will not be less than corePoolSize.
        # It is only used if using a bounded task queue.
        max-pool-size-factor  = 3.0

        # Max number of threads to cap factor-based maximumPoolSize number to
        max-pool-size-max = 64

        # Specifies the bounded capacity of the task queue (&lt; 1 == unbounded)
        task-queue-size = -1

        # Specifies which type of task queue will be used, can be &quot;array&quot; or
        # &quot;linked&quot; (default)
        task-queue-type = &quot;linked&quot;

        # Allow core threads to time out
        allow-core-timeout = on
      }

      # How long time the dispatcher will wait for new actors until it shuts down
      shutdown-timeout = 1s

      # Throughput defines the number of messages that are processed in a batch
      # before the thread is returned to the pool. Set to 1 for as fair as possible.
      throughput = 5

      # Throughput deadline for Dispatcher, set to 0 or negative for no deadline
      throughput-deadline-time = 0ms

      # For BalancingDispatcher: If the balancing dispatcher should attempt to
      # schedule idle actors using the same dispatcher when a message comes in,
      # and the dispatchers ExecutorService is not fully busy already.
      attempt-teamwork = on

      # If this dispatcher requires a specific type of mailbox, specify the
      # fully-qualified class name here; the actually created mailbox will
      # be a subtype of this type. The empty string signifies no requirement.
      mailbox-requirement = &quot;&quot;
    }

    default-mailbox {
      # FQCN of the MailboxType. The Class of the FQCN must have a public
      # constructor with
      # (akka.actor.ActorSystem.Settings, com.typesafe.config.Config) parameters.
      mailbox-type = &quot;akka.dispatch.UnboundedMailbox&quot;

      # If the mailbox is bounded then it uses this setting to determine its
      # capacity. The provided value must be positive.
      # NOTICE:
      # Up to version 2.1 the mailbox type was determined based on this setting;
      # this is no longer the case, the type must explicitly be a bounded mailbox.
      mailbox-capacity = 1000

      # If the mailbox is bounded then this is the timeout for enqueueing
      # in case the mailbox is full. Negative values signify infinite
      # timeout, which should be avoided as it bears the risk of dead-lock.
      mailbox-push-timeout-time = 10s

      # For Actor with Stash: The default capacity of the stash.
      # If negative (or zero) then an unbounded stash is used (default)
      # If positive then a bounded stash is used and the capacity is set using
      # the property
      stash-capacity = -1
    }

    mailbox {
      # Mapping between message queue semantics and mailbox configurations.
      # Used by akka.dispatch.RequiresMessageQueue[T] to enforce different
      # mailbox types on actors.
      # If your Actor implements RequiresMessageQueue[T], then when you create
      # an instance of that actor its mailbox type will be decided by looking
      # up a mailbox configuration via T in this mapping
      requirements {
        &quot;akka.dispatch.UnboundedMessageQueueSemantics&quot; =
          akka.actor.mailbox.unbounded-queue-based
        &quot;akka.dispatch.BoundedMessageQueueSemantics&quot; =
          akka.actor.mailbox.bounded-queue-based
        &quot;akka.dispatch.DequeBasedMessageQueueSemantics&quot; =
          akka.actor.mailbox.unbounded-deque-based
        &quot;akka.dispatch.UnboundedDequeBasedMessageQueueSemantics&quot; =
          akka.actor.mailbox.unbounded-deque-based
        &quot;akka.dispatch.BoundedDequeBasedMessageQueueSemantics&quot; =
          akka.actor.mailbox.bounded-deque-based
        &quot;akka.dispatch.MultipleConsumerSemantics&quot; =
          akka.actor.mailbox.unbounded-queue-based
        &quot;akka.dispatch.ControlAwareMessageQueueSemantics&quot; =
          akka.actor.mailbox.unbounded-control-aware-queue-based
        &quot;akka.dispatch.UnboundedControlAwareMessageQueueSemantics&quot; =
          akka.actor.mailbox.unbounded-control-aware-queue-based
        &quot;akka.dispatch.BoundedControlAwareMessageQueueSemantics&quot; =
          akka.actor.mailbox.bounded-control-aware-queue-based
        &quot;akka.event.LoggerMessageQueueSemantics&quot; =
          akka.actor.mailbox.logger-queue
      }

      unbounded-queue-based {
        # FQCN of the MailboxType, The Class of the FQCN must have a public
        # constructor with (akka.actor.ActorSystem.Settings,
        # com.typesafe.config.Config) parameters.
        mailbox-type = &quot;akka.dispatch.UnboundedMailbox&quot;
      }

      bounded-queue-based {
        # FQCN of the MailboxType, The Class of the FQCN must have a public
        # constructor with (akka.actor.ActorSystem.Settings,
        # com.typesafe.config.Config) parameters.
        mailbox-type = &quot;akka.dispatch.BoundedMailbox&quot;
      }

      unbounded-deque-based {
        # FQCN of the MailboxType, The Class of the FQCN must have a public
        # constructor with (akka.actor.ActorSystem.Settings,
        # com.typesafe.config.Config) parameters.
        mailbox-type = &quot;akka.dispatch.UnboundedDequeBasedMailbox&quot;
      }

      bounded-deque-based {
        # FQCN of the MailboxType, The Class of the FQCN must have a public
        # constructor with (akka.actor.ActorSystem.Settings,
        # com.typesafe.config.Config) parameters.
        mailbox-type = &quot;akka.dispatch.BoundedDequeBasedMailbox&quot;
      }

      unbounded-control-aware-queue-based {
        # FQCN of the MailboxType, The Class of the FQCN must have a public
        # constructor with (akka.actor.ActorSystem.Settings,
        # com.typesafe.config.Config) parameters.
        mailbox-type = &quot;akka.dispatch.UnboundedControlAwareMailbox&quot;
      }

      bounded-control-aware-queue-based {
        # FQCN of the MailboxType, The Class of the FQCN must have a public
        # constructor with (akka.actor.ActorSystem.Settings,
        # com.typesafe.config.Config) parameters.
        mailbox-type = &quot;akka.dispatch.BoundedControlAwareMailbox&quot;
      }
      
      # The LoggerMailbox will drain all messages in the mailbox
      # when the system is shutdown and deliver them to the StandardOutLogger.
      # Do not change this unless you know what you are doing.
      logger-queue {
        mailbox-type = &quot;akka.event.LoggerMailboxType&quot;
      }
    }

    debug {
      # enable function of Actor.loggable(), which is to log any received message
      # at DEBUG level, see the “Testing Actor Systems” section of the Akka
      # Documentation at http://akka.io/docs
      receive = off

      # enable DEBUG logging of all AutoReceiveMessages (Kill, PoisonPill et.c.)
      autoreceive = off

      # enable DEBUG logging of actor lifecycle changes
      lifecycle = off

      # enable DEBUG logging of all LoggingFSMs for events, transitions and timers
      fsm = off

      # enable DEBUG logging of subscription changes on the eventStream
      event-stream = off

      # enable DEBUG logging of unhandled messages
      unhandled = off

      # enable WARN logging of misconfigured routers
      router-misconfiguration = off
    }

    # Entries for pluggable serializers and their bindings.
    serializers {
      java = &quot;akka.serialization.JavaSerializer&quot;
      bytes = &quot;akka.serialization.ByteArraySerializer&quot;
    }

    # Class to Serializer binding. You only need to specify the name of an
    # interface or abstract base class of the messages. In case of ambiguity it
    # is using the most specific configured class, or giving a warning and
    # choosing the “first” one.
    #
    # To disable one of the default serializers, assign its class to &quot;none&quot;, like
    # &quot;java.io.Serializable&quot; = none
    serialization-bindings {
      &quot;[B&quot; = bytes
      &quot;java.io.Serializable&quot; = java
    }
    
    # Set this to on to enable serialization-bindings define in
    # additional-serialization-bindings. Those are by default not included
    # for backwards compatibility reasons. They are enabled by default if
    # akka.remote.artery.enabled=on. 
    enable-additional-serialization-bindings = off
    
    # Additional serialization-bindings that are replacing Java serialization are
    # defined in this section and not included by default for backwards compatibility 
    # reasons. They can be enabled with enable-additional-serialization-bindings=on.
    # They are enabled by default if akka.remote.artery.enabled=on. 
    additional-serialization-bindings {
    }

    # Log warnings when the default Java serialization is used to serialize messages.
    # The default serializer uses Java serialization which is not very performant and should not
    # be used in production environments unless you don&#39;t care about performance. In that case
    # you can turn this off.
    warn-about-java-serializer-usage = on

    # To be used with the above warn-about-java-serializer-usage
    # When warn-about-java-serializer-usage = on, and this warn-on-no-serialization-verification = off,
    # warnings are suppressed for classes extending NoSerializationVerificationNeeded
    # to reduce noize.
    warn-on-no-serialization-verification = on

    # Configuration namespace of serialization identifiers.
    # Each serializer implementation must have an entry in the following format:
    # `akka.actor.serialization-identifiers.&quot;FQCN&quot; = ID`
    # where `FQCN` is fully qualified class name of the serializer implementation
    # and `ID` is globally unique serializer identifier number.
    # Identifier values from 0 to 16 are reserved for Akka internal usage.
    serialization-identifiers {
      &quot;akka.serialization.JavaSerializer&quot; = 1
      &quot;akka.serialization.ByteArraySerializer&quot; = 4
    }

    # Configuration items which are used by the akka.actor.ActorDSL._ methods
    dsl {
      # Maximum queue size of the actor created by newInbox(); this protects
      # against faulty programs which use select() and consistently miss messages
      inbox-size = 1000

      # Default timeout to assume for operations like Inbox.receive et al
      default-timeout = 5s
    }
  }

  # Used to set the behavior of the scheduler.
  # Changing the default values may change the system behavior drastically so make
  # sure you know what you&#39;re doing! See the Scheduler section of the Akka
  # Documentation for more details.
  scheduler {
    # The LightArrayRevolverScheduler is used as the default scheduler in the
    # system. It does not execute the scheduled tasks on exact time, but on every
    # tick, it will run everything that is (over)due. You can increase or decrease
    # the accuracy of the execution timing by specifying smaller or larger tick
    # duration. If you are scheduling a lot of tasks you should consider increasing
    # the ticks per wheel.
    # Note that it might take up to 1 tick to stop the Timer, so setting the
    # tick-duration to a high value will make shutting down the actor system
    # take longer.
    tick-duration = 10ms

    # The timer uses a circular wheel of buckets to store the timer tasks.
    # This should be set such that the majority of scheduled timeouts (for high
    # scheduling frequency) will be shorter than one rotation of the wheel
    # (ticks-per-wheel * ticks-duration)
    # THIS MUST BE A POWER OF TWO!
    ticks-per-wheel = 512

    # This setting selects the timer implementation which shall be loaded at
    # system start-up.
    # The class given here must implement the akka.actor.Scheduler interface
    # and offer a public constructor which takes three arguments:
    #  1) com.typesafe.config.Config
    #  2) akka.event.LoggingAdapter
    #  3) java.util.concurrent.ThreadFactory
    implementation = akka.actor.LightArrayRevolverScheduler

    # When shutting down the scheduler, there will typically be a thread which
    # needs to be stopped, and this timeout determines how long to wait for
    # that to happen. In case of timeout the shutdown of the actor system will
    # proceed without running possibly still enqueued tasks.
    shutdown-timeout = 5s
  }

  io {

    # By default the select loops run on dedicated threads, hence using a
    # PinnedDispatcher
    pinned-dispatcher {
      type = &quot;PinnedDispatcher&quot;
      executor = &quot;thread-pool-executor&quot;
      thread-pool-executor.allow-core-timeout = off
    }

    tcp {

      # The number of selectors to stripe the served channels over; each of
      # these will use one select loop on the selector-dispatcher.
      nr-of-selectors = 1

      # Maximum number of open channels supported by this TCP module; there is
      # no intrinsic general limit, this setting is meant to enable DoS
      # protection by limiting the number of concurrently connected clients.
      # Also note that this is a &quot;soft&quot; limit; in certain cases the implementation
      # will accept a few connections more or a few less than the number configured
      # here. Must be an integer &gt; 0 or &quot;unlimited&quot;.
      max-channels = 256000

      # When trying to assign a new connection to a selector and the chosen
      # selector is at full capacity, retry selector choosing and assignment
      # this many times before giving up
      selector-association-retries = 10

      # The maximum number of connection that are accepted in one go,
      # higher numbers decrease latency, lower numbers increase fairness on
      # the worker-dispatcher
      batch-accept-limit = 10

      # The number of bytes per direct buffer in the pool used to read or write
      # network data from the kernel.
      direct-buffer-size = 128 KiB

      # The maximal number of direct buffers kept in the direct buffer pool for
      # reuse.
      direct-buffer-pool-limit = 1000

      # The duration a connection actor waits for a `Register` message from
      # its commander before aborting the connection.
      register-timeout = 5s

      # The maximum number of bytes delivered by a `Received` message. Before
      # more data is read from the network the connection actor will try to
      # do other work.
      # The purpose of this setting is to impose a smaller limit than the 
      # configured receive buffer size. When using value &#39;unlimited&#39; it will
      # try to read all from the receive buffer.
      max-received-message-size = unlimited

      # Enable fine grained logging of what goes on inside the implementation.
      # Be aware that this may log more than once per message sent to the actors
      # of the tcp implementation.
      trace-logging = off

      # Fully qualified config path which holds the dispatcher configuration
      # to be used for running the select() calls in the selectors
      selector-dispatcher = &quot;akka.io.pinned-dispatcher&quot;

      # Fully qualified config path which holds the dispatcher configuration
      # for the read/write worker actors
      worker-dispatcher = &quot;akka.actor.default-dispatcher&quot;

      # Fully qualified config path which holds the dispatcher configuration
      # for the selector management actors
      management-dispatcher = &quot;akka.actor.default-dispatcher&quot;

      # Fully qualified config path which holds the dispatcher configuration
      # on which file IO tasks are scheduled
      file-io-dispatcher = &quot;akka.actor.default-dispatcher&quot;

      # The maximum number of bytes (or &quot;unlimited&quot;) to transfer in one batch
      # when using `WriteFile` command which uses `FileChannel.transferTo` to
      # pipe files to a TCP socket. On some OS like Linux `FileChannel.transferTo`
      # may block for a long time when network IO is faster than file IO.
      # Decreasing the value may improve fairness while increasing may improve
      # throughput.
      file-io-transferTo-limit = 512 KiB

      # The number of times to retry the `finishConnect` call after being notified about
      # OP_CONNECT. Retries are needed if the OP_CONNECT notification doesn&#39;t imply that
      # `finishConnect` will succeed, which is the case on Android.
      finish-connect-retries = 5

      # On Windows connection aborts are not reliably detected unless an OP_READ is
      # registered on the selector _after_ the connection has been reset. This
      # workaround enables an OP_CONNECT which forces the abort to be visible on Windows.
      # Enabling this setting on other platforms than Windows will cause various failures
      # and undefined behavior.
      # Possible values of this key are on, off and auto where auto will enable the
      # workaround if Windows is detected automatically.
      windows-connection-abort-workaround-enabled = off
    }

    udp {

      # The number of selectors to stripe the served channels over; each of
      # these will use one select loop on the selector-dispatcher.
      nr-of-selectors = 1

      # Maximum number of open channels supported by this UDP module Generally
      # UDP does not require a large number of channels, therefore it is
      # recommended to keep this setting low.
      max-channels = 4096

      # The select loop can be used in two modes:
      # - setting &quot;infinite&quot; will select without a timeout, hogging a thread
      # - setting a positive timeout will do a bounded select call,
      #   enabling sharing of a single thread between multiple selectors
      #   (in this case you will have to use a different configuration for the
      #   selector-dispatcher, e.g. using &quot;type=Dispatcher&quot; with size 1)
      # - setting it to zero means polling, i.e. calling selectNow()
      select-timeout = infinite

      # When trying to assign a new connection to a selector and the chosen
      # selector is at full capacity, retry selector choosing and assignment
      # this many times before giving up
      selector-association-retries = 10

      # The maximum number of datagrams that are read in one go,
      # higher numbers decrease latency, lower numbers increase fairness on
      # the worker-dispatcher
      receive-throughput = 3

      # The number of bytes per direct buffer in the pool used to read or write
      # network data from the kernel.
      direct-buffer-size = 128 KiB

      # The maximal number of direct buffers kept in the direct buffer pool for
      # reuse.
      direct-buffer-pool-limit = 1000

      # Enable fine grained logging of what goes on inside the implementation.
      # Be aware that this may log more than once per message sent to the actors
      # of the tcp implementation.
      trace-logging = off

      # Fully qualified config path which holds the dispatcher configuration
      # to be used for running the select() calls in the selectors
      selector-dispatcher = &quot;akka.io.pinned-dispatcher&quot;

      # Fully qualified config path which holds the dispatcher configuration
      # for the read/write worker actors
      worker-dispatcher = &quot;akka.actor.default-dispatcher&quot;

      # Fully qualified config path which holds the dispatcher configuration
      # for the selector management actors
      management-dispatcher = &quot;akka.actor.default-dispatcher&quot;
    }

    udp-connected {

      # The number of selectors to stripe the served channels over; each of
      # these will use one select loop on the selector-dispatcher.
      nr-of-selectors = 1

      # Maximum number of open channels supported by this UDP module Generally
      # UDP does not require a large number of channels, therefore it is
      # recommended to keep this setting low.
      max-channels = 4096

      # The select loop can be used in two modes:
      # - setting &quot;infinite&quot; will select without a timeout, hogging a thread
      # - setting a positive timeout will do a bounded select call,
      #   enabling sharing of a single thread between multiple selectors
      #   (in this case you will have to use a different configuration for the
      #   selector-dispatcher, e.g. using &quot;type=Dispatcher&quot; with size 1)
      # - setting it to zero means polling, i.e. calling selectNow()
      select-timeout = infinite

      # When trying to assign a new connection to a selector and the chosen
      # selector is at full capacity, retry selector choosing and assignment
      # this many times before giving up
      selector-association-retries = 10

      # The maximum number of datagrams that are read in one go,
      # higher numbers decrease latency, lower numbers increase fairness on
      # the worker-dispatcher
      receive-throughput = 3

      # The number of bytes per direct buffer in the pool used to read or write
      # network data from the kernel.
      direct-buffer-size = 128 KiB

      # The maximal number of direct buffers kept in the direct buffer pool for
      # reuse.
      direct-buffer-pool-limit = 1000
      
      # Enable fine grained logging of what goes on inside the implementation.
      # Be aware that this may log more than once per message sent to the actors
      # of the tcp implementation.
      trace-logging = off

      # Fully qualified config path which holds the dispatcher configuration
      # to be used for running the select() calls in the selectors
      selector-dispatcher = &quot;akka.io.pinned-dispatcher&quot;

      # Fully qualified config path which holds the dispatcher configuration
      # for the read/write worker actors
      worker-dispatcher = &quot;akka.actor.default-dispatcher&quot;

      # Fully qualified config path which holds the dispatcher configuration
      # for the selector management actors
      management-dispatcher = &quot;akka.actor.default-dispatcher&quot;
    }

    dns {
      # Fully qualified config path which holds the dispatcher configuration
      # for the manager and resolver router actors.
      # For actual router configuration see akka.actor.deployment./IO-DNS/*
      dispatcher = &quot;akka.actor.default-dispatcher&quot;

      # Name of the subconfig at path akka.io.dns, see inet-address below
      resolver = &quot;inet-address&quot;

      inet-address {
        # Must implement akka.io.DnsProvider
        provider-object = &quot;akka.io.InetAddressDnsProvider&quot;

        # These TTLs are set to default java 6 values
        positive-ttl = 30s
        negative-ttl = 10s

        # How often to sweep out expired cache entries.
        # Note that this interval has nothing to do with TTLs
        cache-cleanup-interval = 120s
      }
    }
  }


}
</pre></div>
</div>
</div>
<div class="section" id="akka-agent">
<span id="config-akka-agent"></span><h3>akka-agent</h3>
<div class="highlight-none"><div class="highlight"><pre>####################################
# Akka Agent Reference Config File #
####################################

# This is the reference config file that contains all the default settings.
# Make your edits/overrides in your application.conf.

akka {
  agent {

    # The dispatcher used for agent-send-off actor
    send-off-dispatcher {
      executor = thread-pool-executor
      type = PinnedDispatcher
    }

    # The dispatcher used for agent-alter-off actor
    alter-off-dispatcher {
      executor = thread-pool-executor
      type = PinnedDispatcher
    }
  }
}
</pre></div>
</div>
</div>
<div class="section" id="akka-camel">
<span id="config-akka-camel"></span><h3>akka-camel</h3>
<div class="highlight-none"><div class="highlight"><pre>####################################
# Akka Camel Reference Config File #
####################################

# This is the reference config file that contains all the default settings.
# Make your edits/overrides in your application.conf.

akka {
  camel {
    # FQCN of the ContextProvider to be used to create or locate a CamelContext
    # it must implement akka.camel.ContextProvider and have a no-arg constructor
    # the built-in default create a fresh DefaultCamelContext
    context-provider = akka.camel.DefaultContextProvider

    # Whether JMX should be enabled or disabled for the Camel Context
    jmx = off
    # enable/disable streaming cache on the Camel Context
    streamingCache = on
    consumer {
      # Configured setting which determines whether one-way communications
      # between an endpoint and this consumer actor
      # should be auto-acknowledged or application-acknowledged.
      # This flag has only effect when exchange is in-only.
      auto-ack = on

      # When endpoint is out-capable (can produce responses) reply-timeout is the
      # maximum time the endpoint can take to send the response before the message
      # exchange fails. This setting is used for out-capable, in-only,
      # manually acknowledged communication.
      reply-timeout = 1m

      # The duration of time to await activation of an endpoint.
      activation-timeout = 10s
    }

    #Scheme to FQCN mappings for CamelMessage body conversions
    conversions {
      &quot;file&quot; = &quot;java.io.InputStream&quot;
    }
  }
}
</pre></div>
</div>
</div>
<div class="section" id="akka-cluster">
<span id="config-akka-cluster"></span><h3>akka-cluster</h3>
<div class="highlight-none"><div class="highlight"><pre>######################################
# Akka Cluster Reference Config File #
######################################

# This is the reference config file that contains all the default settings.
# Make your edits/overrides in your application.conf.

akka {

  cluster {
    # Initial contact points of the cluster.
    # The nodes to join automatically at startup.
    # Comma separated full URIs defined by a string on the form of
    # &quot;akka.tcp://system@hostname:port&quot;
    # Leave as empty if the node is supposed to be joined manually.
    seed-nodes = []

    # how long to wait for one of the seed nodes to reply to initial join request
    seed-node-timeout = 5s

    # If a join request fails it will be retried after this period.
    # Disable join retry by specifying &quot;off&quot;.
    retry-unsuccessful-join-after = 10s

    # Should the &#39;leader&#39; in the cluster be allowed to automatically mark
    # unreachable nodes as DOWN after a configured time of unreachability?
    # Using auto-down implies that two separate clusters will automatically be
    # formed in case of network partition.
    #
    # Don&#39;t enable this in production, see &#39;Auto-downing (DO NOT USE)&#39; section 
    # of Akka Cluster documentation.
    #
    # Disable with &quot;off&quot; or specify a duration to enable auto-down.
    # If a downing-provider-class is configured this setting is ignored.
    auto-down-unreachable-after = off
    
    # Time margin after which shards or singletons that belonged to a downed/removed
    # partition are created in surviving partition. The purpose of this margin is that 
    # in case of a network partition the persistent actors in the non-surviving partitions
    # must be stopped before corresponding persistent actors are started somewhere else.
    # This is useful if you implement downing strategies that handle network partitions,
    # e.g. by keeping the larger side of the partition and shutting down the smaller side.
    # It will not add any extra safety for auto-down-unreachable-after, since that is not
    # handling network partitions. 
    # Disable with &quot;off&quot; or specify a duration to enable.
    down-removal-margin = off

    # Pluggable support for downing of nodes in the cluster.
    # If this setting is left empty behaviour will depend on &#39;auto-down-unreachable&#39; in the following ways:
    # * if it is &#39;off&#39; the `NoDowning` provider is used and no automatic downing will be performed
    # * if it is set to a duration the `AutoDowning` provider is with the configured downing duration
    #
    # If specified the value must be the fully qualified class name of a subclass of
    # `akka.cluster.DowningProvider` having a public one argument constructor accepting an `ActorSystem`
    downing-provider-class = &quot;&quot;

    # Artery only setting
    # When a node has been gracefully removed, let this time pass (to allow for example
    # cluster singleton handover to complete) and then quarantine the removed node.
    quarantine-removed-node-after=30s

    # By default, the leader will not move &#39;Joining&#39; members to &#39;Up&#39; during a network
    # split. This feature allows the leader to accept &#39;Joining&#39; members to be &#39;WeaklyUp&#39;
    # so they become part of the cluster even during a network split. The leader will
    # move &#39;WeaklyUp&#39; members to &#39;Up&#39; status once convergence has been reached. This
    # feature must be off if some members are running Akka 2.3.X.
    # WeaklyUp is an EXPERIMENTAL feature.
    allow-weakly-up-members = off

    # The roles of this member. List of strings, e.g. roles = [&quot;A&quot;, &quot;B&quot;].
    # The roles are part of the membership information and can be used by
    # routers or other services to distribute work to certain member types,
    # e.g. front-end and back-end nodes.
    roles = []

    role {
      # Minimum required number of members of a certain role before the leader
      # changes member status of &#39;Joining&#39; members to &#39;Up&#39;. Typically used together
      # with &#39;Cluster.registerOnMemberUp&#39; to defer some action, such as starting
      # actors, until the cluster has reached a certain size.
      # E.g. to require 2 nodes with role &#39;frontend&#39; and 3 nodes with role &#39;backend&#39;:
      #   frontend.min-nr-of-members = 2
      #   backend.min-nr-of-members = 3
      #&lt;role-name&gt;.min-nr-of-members = 1
    }

    # Minimum required number of members before the leader changes member status
    # of &#39;Joining&#39; members to &#39;Up&#39;. Typically used together with
    # &#39;Cluster.registerOnMemberUp&#39; to defer some action, such as starting actors,
    # until the cluster has reached a certain size.
    min-nr-of-members = 1

    # Enable/disable info level logging of cluster events
    log-info = on

    # Enable or disable JMX MBeans for management of the cluster
    jmx.enabled = on

    # how long should the node wait before starting the periodic tasks
    # maintenance tasks?
    periodic-tasks-initial-delay = 1s

    # how often should the node send out gossip information?
    gossip-interval = 1s
    
    # discard incoming gossip messages if not handled within this duration
    gossip-time-to-live = 2s

    # how often should the leader perform maintenance tasks?
    leader-actions-interval = 1s

    # how often should the node move nodes, marked as unreachable by the failure
    # detector, out of the membership ring?
    unreachable-nodes-reaper-interval = 1s

    # How often the current internal stats should be published.
    # A value of 0s can be used to always publish the stats, when it happens.
    # Disable with &quot;off&quot;.
    publish-stats-interval = off

    # The id of the dispatcher to use for cluster actors. If not specified
    # default dispatcher is used.
    # If specified you need to define the settings of the actual dispatcher.
    use-dispatcher = &quot;&quot;

    # Gossip to random node with newer or older state information, if any with
    # this probability. Otherwise Gossip to any random live node.
    # Probability value is between 0.0 and 1.0. 0.0 means never, 1.0 means always.
    gossip-different-view-probability = 0.8
    
    # Reduced the above probability when the number of nodes in the cluster
    # greater than this value.
    reduce-gossip-different-view-probability = 400

    # Settings for the Phi accrual failure detector (http://www.jaist.ac.jp/~defago/files/pdf/IS_RR_2004_010.pdf
    # [Hayashibara et al]) used by the cluster subsystem to detect unreachable
    # members.
    # The default PhiAccrualFailureDetector will trigger if there are no heartbeats within
    # the duration heartbeat-interval + acceptable-heartbeat-pause + threshold_adjustment,
    # i.e. around 5.5 seconds with default settings.
    failure-detector {

      # FQCN of the failure detector implementation.
      # It must implement akka.remote.FailureDetector and have
      # a public constructor with a com.typesafe.config.Config and
      # akka.actor.EventStream parameter.
      implementation-class = &quot;akka.remote.PhiAccrualFailureDetector&quot;

      # How often keep-alive heartbeat messages should be sent to each connection.
      heartbeat-interval = 1 s

      # Defines the failure detector threshold.
      # A low threshold is prone to generate many wrong suspicions but ensures
      # a quick detection in the event of a real crash. Conversely, a high
      # threshold generates fewer mistakes but needs more time to detect
      # actual crashes.
      threshold = 8.0

      # Number of the samples of inter-heartbeat arrival times to adaptively
      # calculate the failure timeout for connections.
      max-sample-size = 1000

      # Minimum standard deviation to use for the normal distribution in
      # AccrualFailureDetector. Too low standard deviation might result in
      # too much sensitivity for sudden, but normal, deviations in heartbeat
      # inter arrival times.
      min-std-deviation = 100 ms

      # Number of potentially lost/delayed heartbeats that will be
      # accepted before considering it to be an anomaly.
      # This margin is important to be able to survive sudden, occasional,
      # pauses in heartbeat arrivals, due to for example garbage collect or
      # network drop.
      acceptable-heartbeat-pause = 3 s

      # Number of member nodes that each member will send heartbeat messages to,
      # i.e. each node will be monitored by this number of other nodes.
      monitored-by-nr-of-members = 5
      
      # After the heartbeat request has been sent the first failure detection
      # will start after this period, even though no heartbeat message has
      # been received.
      expected-response-after = 1 s

    }

    metrics {
      # Enable or disable metrics collector for load-balancing nodes.
      enabled = on

      # FQCN of the metrics collector implementation.
      # It must implement akka.cluster.MetricsCollector and
      # have public constructor with akka.actor.ActorSystem parameter.
      # The default SigarMetricsCollector uses JMX and Hyperic SIGAR, if SIGAR
      # is on the classpath, otherwise only JMX.
      collector-class = &quot;akka.cluster.SigarMetricsCollector&quot;

      # How often metrics are sampled on a node.
      # Shorter interval will collect the metrics more often.
      collect-interval = 3s

      # How often a node publishes metrics information.
      gossip-interval = 3s

      # How quickly the exponential weighting of past data is decayed compared to
      # new data. Set lower to increase the bias toward newer values.
      # The relevance of each data sample is halved for every passing half-life
      # duration, i.e. after 4 times the half-life, a data sample’s relevance is
      # reduced to 6% of its original relevance. The initial relevance of a data
      # sample is given by 1 – 0.5 ^ (collect-interval / half-life).
      # See http://en.wikipedia.org/wiki/Moving_average#Exponential_moving_average
      moving-average-half-life = 12s
    }

    # If the tick-duration of the default scheduler is longer than the
    # tick-duration configured here a dedicated scheduler will be used for
    # periodic tasks of the cluster, otherwise the default scheduler is used.
    # See akka.scheduler settings for more details.
    scheduler {
      tick-duration = 33ms
      ticks-per-wheel = 512
    }

    debug {
      # log heartbeat events (very verbose, useful mostly when debugging heartbeating issues)
      verbose-heartbeat-logging = off
    }

  }

  # Default configuration for routers
  actor.deployment.default {
    # MetricsSelector to use
    # - available: &quot;mix&quot;, &quot;heap&quot;, &quot;cpu&quot;, &quot;load&quot;
    # - or: Fully qualified class name of the MetricsSelector class.
    #       The class must extend akka.cluster.routing.MetricsSelector
    #       and have a public constructor with com.typesafe.config.Config
    #       parameter.
    # - default is &quot;mix&quot;
    metrics-selector = mix
  }
  actor.deployment.default.cluster {
    # enable cluster aware router that deploys to nodes in the cluster
    enabled = off

    # Maximum number of routees that will be deployed on each cluster
    # member node.
    # Note that max-total-nr-of-instances defines total number of routees, but
    # number of routees per node will not be exceeded, i.e. if you
    # define max-total-nr-of-instances = 50 and max-nr-of-instances-per-node = 2
    # it will deploy 2 routees per new member in the cluster, up to
    # 25 members.
    max-nr-of-instances-per-node = 1
    
    # Maximum number of routees that will be deployed, in total
    # on all nodes. See also description of max-nr-of-instances-per-node.
    # For backwards compatibility reasons, nr-of-instances
    # has the same purpose as max-total-nr-of-instances for cluster
    # aware routers and nr-of-instances (if defined by user) takes
    # precedence over max-total-nr-of-instances. 
    max-total-nr-of-instances = 10000

    # Defines if routees are allowed to be located on the same node as
    # the head router actor, or only on remote nodes.
    # Useful for master-worker scenario where all routees are remote.
    allow-local-routees = on

    # Use members with specified role, or all members if undefined or empty.
    use-role = &quot;&quot;

  }

  # Protobuf serializer for cluster messages
  actor {
    serializers {
      akka-cluster = &quot;akka.cluster.protobuf.ClusterMessageSerializer&quot;
    }

    serialization-bindings {
      &quot;akka.cluster.ClusterMessage&quot; = akka-cluster
    }
    
    serialization-identifiers {
      &quot;akka.cluster.protobuf.ClusterMessageSerializer&quot; = 5
    }
    
    router.type-mapping {
      adaptive-pool = &quot;akka.cluster.routing.AdaptiveLoadBalancingPool&quot;
      adaptive-group = &quot;akka.cluster.routing.AdaptiveLoadBalancingGroup&quot;
    }
  }

}
</pre></div>
</div>
</div>
<div class="section" id="akka-multi-node-testkit">
<span id="config-akka-multi-node-testkit"></span><h3>akka-multi-node-testkit</h3>
<div class="highlight-none"><div class="highlight"><pre>#############################################
# Akka Remote Testing Reference Config File #
#############################################

# This is the reference config file that contains all the default settings.
# Make your edits/overrides in your application.conf.

akka {
  testconductor {

    # Timeout for joining a barrier: this is the maximum time any participants
    # waits for everybody else to join a named barrier.
    barrier-timeout = 30s
    
    # Timeout for interrogation of TestConductor’s Controller actor
    query-timeout = 10s
    
    # Threshold for packet size in time unit above which the failure injector will
    # split the packet and deliver in smaller portions; do not give value smaller
    # than HashedWheelTimer resolution (would not make sense)
    packet-split-threshold = 100ms
    
    # amount of time for the ClientFSM to wait for the connection to the conductor
    # to be successful
    connect-timeout = 20s
    
    # Number of connect attempts to be made to the conductor controller
    client-reconnects = 30
    
    # minimum time interval which is to be inserted between reconnect attempts
    reconnect-backoff = 1s

    netty {
      # (I&amp;O) Used to configure the number of I/O worker threads on server sockets
      server-socket-worker-pool {
        # Min number of threads to cap factor-based number to
        pool-size-min = 1

        # The pool size factor is used to determine thread pool size
        # using the following formula: ceil(available processors * factor).
        # Resulting size is then bounded by the pool-size-min and
        # pool-size-max values.
        pool-size-factor = 1.0

        # Max number of threads to cap factor-based number to
        pool-size-max = 2
      }

      # (I&amp;O) Used to configure the number of I/O worker threads on client sockets
      client-socket-worker-pool {
        # Min number of threads to cap factor-based number to
        pool-size-min = 1

        # The pool size factor is used to determine thread pool size
        # using the following formula: ceil(available processors * factor).
        # Resulting size is then bounded by the pool-size-min and
        # pool-size-max values.
        pool-size-factor = 1.0

        # Max number of threads to cap factor-based number to
        pool-size-max = 2
      }
    }
  }
}
</pre></div>
</div>
</div>
<div class="section" id="akka-persistence">
<span id="config-akka-persistence"></span><h3>akka-persistence</h3>
<div class="highlight-none"><div class="highlight"><pre>###########################################################
# Akka Persistence Extension Reference Configuration File #
###########################################################

# This is the reference config file that contains all the default settings.
# Make your edits in your application.conf in order to override these settings.

# Directory of persistence journal and snapshot store plugins is available at the 
# Akka Community Projects page http://akka.io/community/

# Default persistence extension settings.
akka.persistence {
    # Fully qualified class name providing a default internal stash overflow strategy.
    # It needs to be a subclass of akka.persistence.StashOverflowStrategyConfigurator.
    # The default strategy throws StashOverflowException.
    internal-stash-overflow-strategy = &quot;akka.persistence.ThrowExceptionConfigurator&quot;
    journal {
        # Absolute path to the journal plugin configuration entry used by 
        # persistent actor or view by default.
        # Persistent actor or view can override `journalPluginId` method 
        # in order to rely on a different journal plugin.
        plugin = &quot;&quot;
        # List of journal plugins to start automatically. Use &quot;&quot; for the default journal plugin.
        auto-start-journals = []
    }
    snapshot-store {
        # Absolute path to the snapshot plugin configuration entry used by
        # persistent actor or view by default.
        # Persistent actor or view can override `snapshotPluginId` method
        # in order to rely on a different snapshot plugin.
        # It is not mandatory to specify a snapshot store plugin.
        # If you don&#39;t use snapshots you don&#39;t have to configure it.
        # Note that Cluster Sharding is using snapshots, so if you
        # use Cluster Sharding you need to define a snapshot store plugin. 
        plugin = &quot;&quot;
        # List of snapshot stores to start automatically. Use &quot;&quot; for the default snapshot store.
        auto-start-snapshot-stores = []
    }
    # used as default-snapshot store if no plugin configured 
    # (see `akka.persistence.snapshot-store`)
    no-snapshot-store {
      class = &quot;akka.persistence.snapshot.NoSnapshotStore&quot;
    }
    # Default persistent view settings.
    view {
        # Automated incremental view update.
        auto-update = on
        # Interval between incremental updates.
        auto-update-interval = 5s
        # Maximum number of messages to replay per incremental view update. 
        # Set to -1 for no upper limit.
        auto-update-replay-max = -1
    }
    # Default reliable delivery settings.
    at-least-once-delivery {
        # Interval between re-delivery attempts.
        redeliver-interval = 5s
        # Maximum number of unconfirmed messages that will be sent in one 
        # re-delivery burst.
        redelivery-burst-limit = 10000
        # After this number of delivery attempts a 
        # `ReliableRedelivery.UnconfirmedWarning`, message will be sent to the actor.
        warn-after-number-of-unconfirmed-attempts = 5
        # Maximum number of unconfirmed messages that an actor with 
        # AtLeastOnceDelivery is allowed to hold in memory.
        max-unconfirmed-messages = 100000
    }
    # Default persistent extension thread pools.
    dispatchers {
        # Dispatcher used by every plugin which does not declare explicit
        # `plugin-dispatcher` field.
        default-plugin-dispatcher {
            type = PinnedDispatcher
            executor = &quot;thread-pool-executor&quot;
        }
        # Default dispatcher for message replay.
        default-replay-dispatcher {
            type = Dispatcher
            executor = &quot;fork-join-executor&quot;
            fork-join-executor {
                parallelism-min = 2
                parallelism-max = 8
            }
        }
        # Default dispatcher for streaming snapshot IO
        default-stream-dispatcher {
            type = Dispatcher
            executor = &quot;fork-join-executor&quot;
            fork-join-executor {
                parallelism-min = 2
                parallelism-max = 8
            }
        }
    }

    # Fallback settings for journal plugin configurations.
    # These settings are used if they are not defined in plugin config section.
    journal-plugin-fallback {

      # Fully qualified class name providing journal plugin api implementation.
      # It is mandatory to specify this property.
      # The class must have a constructor without parameters or constructor with
      # one `com.typesafe.config.Config` parameter.
      class = &quot;&quot;

      # Dispatcher for the plugin actor.
      plugin-dispatcher = &quot;akka.persistence.dispatchers.default-plugin-dispatcher&quot;

      # Dispatcher for message replay.
      replay-dispatcher = &quot;akka.persistence.dispatchers.default-replay-dispatcher&quot;

      # Removed: used to be the Maximum size of a persistent message batch written to the journal.
      # Now this setting is without function, PersistentActor will write as many messages
      # as it has accumulated since the last write.
      max-message-batch-size = 200

      # If there is more time in between individual events gotten from the journal
      # recovery than this the recovery will fail.
      # Note that it also affects reading the snapshot before replaying events on
      # top of it, even though it is configured for the journal.
      recovery-event-timeout = 30s

      circuit-breaker {
        max-failures = 10
        call-timeout = 10s
        reset-timeout = 30s
      }

      # The replay filter can detect a corrupt event stream by inspecting
      # sequence numbers and writerUuid when replaying events.
      replay-filter {
        # What the filter should do when detecting invalid events.
        # Supported values:
        # `repair-by-discard-old` : discard events from old writers,
        #                           warning is logged
        # `fail` : fail the replay, error is logged
        # `warn` : log warning but emit events untouched
        # `off` : disable this feature completely
        mode = repair-by-discard-old

        # It uses a look ahead buffer for analyzing the events.
        # This defines the size (in number of events) of the buffer.
        window-size = 100

        # How many old writerUuid to remember
        max-old-writers = 10

        # Set this to `on` to enable detailed debug logging of each
        # replayed event.
        debug = off
      }
    }

    # Fallback settings for snapshot store plugin configurations
    # These settings are used if they are not defined in plugin config section.
    snapshot-store-plugin-fallback {

      # Fully qualified class name providing snapshot store plugin api
      # implementation. It is mandatory to specify this property if
      # snapshot store is enabled.
      # The class must have a constructor without parameters or constructor with
      # one `com.typesafe.config.Config` parameter.
      class = &quot;&quot;

      # Dispatcher for the plugin actor.
      plugin-dispatcher = &quot;akka.persistence.dispatchers.default-plugin-dispatcher&quot;

      circuit-breaker {
        max-failures = 5
        call-timeout = 20s
        reset-timeout = 60s
      }
    }
}

# Protobuf serialization for the persistent extension messages.
akka.actor {
    serializers {
        akka-persistence-message = &quot;akka.persistence.serialization.MessageSerializer&quot;
        akka-persistence-snapshot = &quot;akka.persistence.serialization.SnapshotSerializer&quot;
    }
    serialization-bindings {
        &quot;akka.persistence.serialization.Message&quot; = akka-persistence-message
        &quot;akka.persistence.serialization.Snapshot&quot; = akka-persistence-snapshot
    }
    serialization-identifiers {
        &quot;akka.persistence.serialization.MessageSerializer&quot; = 7
        &quot;akka.persistence.serialization.SnapshotSerializer&quot; = 8
    }
}


###################################################
# Persistence plugins included with the extension #
###################################################

# In-memory journal plugin.
akka.persistence.journal.inmem {
    # Class name of the plugin.
    class = &quot;akka.persistence.journal.inmem.InmemJournal&quot;
    # Dispatcher for the plugin actor.
    plugin-dispatcher = &quot;akka.actor.default-dispatcher&quot;
}

# Local file system snapshot store plugin.
akka.persistence.snapshot-store.local {
    # Class name of the plugin.
    class = &quot;akka.persistence.snapshot.local.LocalSnapshotStore&quot;
    # Dispatcher for the plugin actor.
    plugin-dispatcher = &quot;akka.persistence.dispatchers.default-plugin-dispatcher&quot;
    # Dispatcher for streaming snapshot IO.
    stream-dispatcher = &quot;akka.persistence.dispatchers.default-stream-dispatcher&quot;
    # Storage location of snapshot files.
    dir = &quot;snapshots&quot;
    # Number load attempts when recovering from the latest snapshot fails
    # yet older snapshot files are available. Each recovery attempt will try
    # to recover using an older than previously failed-on snapshot file 
    # (if any are present).
    max-load-attempts = 3
}

# LevelDB journal plugin.
# Note: this plugin requires explicit LevelDB dependency, see below. 
akka.persistence.journal.leveldb {
    # Class name of the plugin.
    class = &quot;akka.persistence.journal.leveldb.LeveldbJournal&quot;
    # Dispatcher for the plugin actor.
    plugin-dispatcher = &quot;akka.persistence.dispatchers.default-plugin-dispatcher&quot;
    # Dispatcher for message replay.
    replay-dispatcher = &quot;akka.persistence.dispatchers.default-replay-dispatcher&quot;
    # Storage location of LevelDB files.
    dir = &quot;journal&quot;
    # Use fsync on write.
    fsync = on
    # Verify checksum on read.
    checksum = off
    # Native LevelDB (via JNI) or LevelDB Java port.
    native = on
}

# Shared LevelDB journal plugin (for testing only).
# Note: this plugin requires explicit LevelDB dependency, see below. 
akka.persistence.journal.leveldb-shared {
    # Class name of the plugin.
    class = &quot;akka.persistence.journal.leveldb.SharedLeveldbJournal&quot;
    # Dispatcher for the plugin actor.
    plugin-dispatcher = &quot;akka.actor.default-dispatcher&quot;
    # Timeout for async journal operations.
    timeout = 10s
    store {
        # Dispatcher for shared store actor.
        store-dispatcher = &quot;akka.persistence.dispatchers.default-plugin-dispatcher&quot;
        # Dispatcher for message replay.
        replay-dispatcher = &quot;akka.persistence.dispatchers.default-replay-dispatcher&quot;
        # Storage location of LevelDB files.
        dir = &quot;journal&quot;
        # Use fsync on write.
        fsync = on
        # Verify checksum on read.
        checksum = off
        # Native LevelDB (via JNI) or LevelDB Java port.
        native = on
    }
}

akka.persistence.journal.proxy {
  # Class name of the plugin.
  class = &quot;akka.persistence.journal.PersistencePluginProxy&quot;
  # Dispatcher for the plugin actor.
  plugin-dispatcher = &quot;akka.actor.default-dispatcher&quot;
  # Set this to on in the configuration of the ActorSystem
  # that will host the target journal
  start-target-journal = off
  # The journal plugin config path to use for the target journal
  target-journal-plugin = &quot;&quot;
  # The address of the proxy to connect to from other nodes. Optional setting.
  target-journal-address = &quot;&quot;
  # Initialization timeout of target lookup
  init-timeout = 10s
}

akka.persistence.snapshot-store.proxy {
  # Class name of the plugin.
  class = &quot;akka.persistence.journal.PersistencePluginProxy&quot;
  # Dispatcher for the plugin actor.
  plugin-dispatcher = &quot;akka.actor.default-dispatcher&quot;
  # Set this to on in the configuration of the ActorSystem
  # that will host the target snapshot-store
  start-target-snapshot-store = off
  # The journal plugin config path to use for the target snapshot-store
  target-snapshot-store-plugin = &quot;&quot;
  # The address of the proxy to connect to from other nodes. Optional setting.
  target-snapshot-store-address = &quot;&quot;
  # Initialization timeout of target lookup
  init-timeout = 10s
}

# LevelDB persistence requires the following dependency declarations:
#
# SBT:
#       &quot;org.iq80.leveldb&quot;            % &quot;leveldb&quot;          % &quot;0.7&quot;
#       &quot;org.fusesource.leveldbjni&quot;   % &quot;leveldbjni-all&quot;   % &quot;1.8&quot;
#
# Maven:
#        &lt;dependency&gt;
#            &lt;groupId&gt;org.iq80.leveldb&lt;/groupId&gt;
#            &lt;artifactId&gt;leveldb&lt;/artifactId&gt;
#            &lt;version&gt;0.7&lt;/version&gt;
#        &lt;/dependency&gt;
#        &lt;dependency&gt;
#            &lt;groupId&gt;org.fusesource.leveldbjni&lt;/groupId&gt;
#            &lt;artifactId&gt;leveldbjni-all&lt;/artifactId&gt;
#            &lt;version&gt;1.8&lt;/version&gt;
#        &lt;/dependency&gt;
</pre></div>
</div>
</div>
<div class="section" id="akka-remote">
<span id="config-akka-remote"></span><h3>akka-remote</h3>
<div class="highlight-none"><div class="highlight"><pre>#####################################
# Akka Remote Reference Config File #
#####################################

# This is the reference config file that contains all the default settings.
# Make your edits/overrides in your application.conf.

# comments about akka.actor settings left out where they are already in akka-
# actor.jar, because otherwise they would be repeated in config rendering.
#
# For the configuration of the new remoting implementation (Artery) please look
# at the bottom section of this file as it is listed separately.

akka {

  actor {

    serializers {
      akka-containers = &quot;akka.remote.serialization.MessageContainerSerializer&quot;
      akka-misc = &quot;akka.remote.serialization.MiscMessageSerializer&quot;
      artery = &quot;akka.remote.serialization.ArteryMessageSerializer&quot;
      proto = &quot;akka.remote.serialization.ProtobufSerializer&quot;
      daemon-create = &quot;akka.remote.serialization.DaemonMsgCreateSerializer&quot;
      primitive-long = &quot;akka.remote.serialization.LongSerializer&quot;
      primitive-int = &quot;akka.remote.serialization.IntSerializer&quot;
      primitive-string = &quot;akka.remote.serialization.StringSerializer&quot;
      primitive-bytestring = &quot;akka.remote.serialization.ByteStringSerializer&quot;
      akka-system-msg = &quot;akka.remote.serialization.SystemMessageSerializer&quot;
    }

    serialization-bindings {
      &quot;akka.actor.ActorSelectionMessage&quot; = akka-containers

      &quot;akka.remote.DaemonMsgCreate&quot; = daemon-create

      &quot;akka.remote.artery.ArteryMessage&quot; = artery

      # Since akka.protobuf.Message does not extend Serializable but
      # GeneratedMessage does, need to use the more specific one here in order
      # to avoid ambiguity.
      &quot;akka.protobuf.GeneratedMessage&quot; = proto

      # Since com.google.protobuf.Message does not extend Serializable but
      # GeneratedMessage does, need to use the more specific one here in order
      # to avoid ambiguity.
      # This com.google.protobuf serialization binding is only used if the class can be loaded,
      # i.e. com.google.protobuf dependency has been added in the application project.
      &quot;com.google.protobuf.GeneratedMessage&quot; = proto
    }

    # For the purpose of preserving protocol backward compatibility these bindings are not
    # included by default. They can be enabled with enable-additional-serialization-bindings=on.
    # They are enabled by default if akka.remote.artery.enabled=on.
    additional-serialization-bindings {
      &quot;akka.actor.Identify&quot; = akka-misc
      &quot;akka.actor.ActorIdentity&quot; = akka-misc
      &quot;scala.Some&quot; = akka-misc
      &quot;scala.None$&quot; = akka-misc
      &quot;akka.actor.Status$Success&quot; = akka-misc
      &quot;akka.actor.Status$Failure&quot; = akka-misc
      &quot;akka.actor.ActorRef&quot; = akka-misc
      &quot;akka.actor.PoisonPill$&quot; = akka-misc
      &quot;akka.actor.Kill$&quot; = akka-misc
      &quot;akka.remote.RemoteWatcher$Heartbeat$&quot; = akka-misc
      &quot;akka.remote.RemoteWatcher$HeartbeatRsp&quot; = akka-misc
      &quot;akka.actor.ActorInitializationException&quot; = akka-misc

      &quot;akka.dispatch.sysmsg.SystemMessage&quot; = akka-system-msg

      &quot;java.lang.String&quot; = primitive-string
      &quot;akka.util.ByteString$ByteString1C&quot; = primitive-bytestring
      &quot;akka.util.ByteString$ByteString1&quot; = primitive-bytestring
      &quot;akka.util.ByteString$ByteStrings&quot; = primitive-bytestring
      &quot;java.lang.Long&quot; = primitive-long
      &quot;scala.Long&quot; = primitive-long
      &quot;java.lang.Integer&quot; = primitive-int
      &quot;scala.Int&quot; = primitive-int

      # Java Serializer is by default used for exceptions.
      # It&#39;s recommended that you implement custom serializer for exceptions that are
      # sent remotely, e.g. in akka.actor.Status.Failure for ask replies. You can add
      # binding to akka-misc (MiscMessageSerializerSpec) for the exceptions that have
      # a constructor with single message String or constructor with message String as
      # first parameter and cause Throwable as second parameter. Note that it&#39;s not
      # safe to add this binding for general exceptions such as IllegalArgumentException
      # because it may have a subclass without required constructor.
      &quot;java.lang.Throwable&quot; = java
      &quot;akka.actor.IllegalActorStateException&quot; = akka-misc
      &quot;akka.actor.ActorKilledException&quot; = akka-misc
      &quot;akka.actor.InvalidActorNameException&quot; = akka-misc
      &quot;akka.actor.InvalidMessageException&quot; = akka-misc
    }

    serialization-identifiers {
      &quot;akka.remote.serialization.ProtobufSerializer&quot; = 2
      &quot;akka.remote.serialization.DaemonMsgCreateSerializer&quot; = 3
      &quot;akka.remote.serialization.MessageContainerSerializer&quot; = 6
      &quot;akka.remote.serialization.MiscMessageSerializer&quot; = 16
      &quot;akka.remote.serialization.ArteryMessageSerializer&quot; = 17
      &quot;akka.remote.serialization.LongSerializer&quot; = 18
      &quot;akka.remote.serialization.IntSerializer&quot; = 19
      &quot;akka.remote.serialization.StringSerializer&quot; = 20
      &quot;akka.remote.serialization.ByteStringSerializer&quot; = 21
      &quot;akka.remote.serialization.SystemMessageSerializer&quot; = 22
    }

    deployment {

      default {

        # if this is set to a valid remote address, the named actor will be
        # deployed at that node e.g. &quot;akka.tcp://sys@host:port&quot;
        remote = &quot;&quot;

        target {

          # A list of hostnames and ports for instantiating the children of a
          # router
          #   The format should be on &quot;akka.tcp://sys@host:port&quot;, where:
          #    - sys is the remote actor system name
          #    - hostname can be either hostname or IP address the remote actor
          #      should connect to
          #    - port should be the port for the remote server on the other node
          # The number of actor instances to be spawned is still taken from the
          # nr-of-instances setting as for local routers; the instances will be
          # distributed round-robin among the given nodes.
          nodes = []

        }
      }
    }
  }

  remote {
    ### Settings shared by classic remoting and Artery (the new implementation of remoting)

    # If set to a nonempty string remoting will use the given dispatcher for
    # its internal actors otherwise the default dispatcher is used. Please note
    # that since remoting can load arbitrary 3rd party drivers (see
    # &quot;enabled-transport&quot; and &quot;adapters&quot; entries) it is not guaranteed that
    # every module will respect this setting.
    use-dispatcher = &quot;akka.remote.default-remote-dispatcher&quot;

    # Settings for the failure detector to monitor connections.
    # For TCP it is not important to have fast failure detection, since
    # most connection failures are captured by TCP itself.
    # The default DeadlineFailureDetector will trigger if there are no heartbeats within
    # the duration heartbeat-interval + acceptable-heartbeat-pause, i.e. 20 seconds
    # with the default settings.
    transport-failure-detector {

      # FQCN of the failure detector implementation.
      # It must implement akka.remote.FailureDetector and have
      # a public constructor with a com.typesafe.config.Config and
      # akka.actor.EventStream parameter.
      implementation-class = &quot;akka.remote.DeadlineFailureDetector&quot;

      # How often keep-alive heartbeat messages should be sent to each connection.
      heartbeat-interval = 4 s

      # Number of potentially lost/delayed heartbeats that will be
      # accepted before considering it to be an anomaly.
      # A margin to the `heartbeat-interval` is important to be able to survive sudden,
      # occasional, pauses in heartbeat arrivals, due to for example garbage collect or
      # network drop.
      acceptable-heartbeat-pause = 16 s
    }

    # Settings for the Phi accrual failure detector (http://www.jaist.ac.jp/~defago/files/pdf/IS_RR_2004_010.pdf
    # [Hayashibara et al]) used for remote death watch.
    # The default PhiAccrualFailureDetector will trigger if there are no heartbeats within
    # the duration heartbeat-interval + acceptable-heartbeat-pause + threshold_adjustment,
    # i.e. around 12.5 seconds with default settings.
    watch-failure-detector {

      # FQCN of the failure detector implementation.
      # It must implement akka.remote.FailureDetector and have
      # a public constructor with a com.typesafe.config.Config and
      # akka.actor.EventStream parameter.
      implementation-class = &quot;akka.remote.PhiAccrualFailureDetector&quot;

      # How often keep-alive heartbeat messages should be sent to each connection.
      heartbeat-interval = 1 s

      # Defines the failure detector threshold.
      # A low threshold is prone to generate many wrong suspicions but ensures
      # a quick detection in the event of a real crash. Conversely, a high
      # threshold generates fewer mistakes but needs more time to detect
      # actual crashes.
      threshold = 10.0

      # Number of the samples of inter-heartbeat arrival times to adaptively
      # calculate the failure timeout for connections.
      max-sample-size = 200

      # Minimum standard deviation to use for the normal distribution in
      # AccrualFailureDetector. Too low standard deviation might result in
      # too much sensitivity for sudden, but normal, deviations in heartbeat
      # inter arrival times.
      min-std-deviation = 100 ms

      # Number of potentially lost/delayed heartbeats that will be
      # accepted before considering it to be an anomaly.
      # This margin is important to be able to survive sudden, occasional,
      # pauses in heartbeat arrivals, due to for example garbage collect or
      # network drop.
      acceptable-heartbeat-pause = 10 s


      # How often to check for nodes marked as unreachable by the failure
      # detector
      unreachable-nodes-reaper-interval = 1s

      # After the heartbeat request has been sent the first failure detection
      # will start after this period, even though no heartbeat mesage has
      # been received.
      expected-response-after = 1 s

    }

    ### Configuration for classic remoting

    # Timeout after which the startup of the remoting subsystem is considered
    # to be failed. Increase this value if your transport drivers (see the
    # enabled-transports section) need longer time to be loaded.
    startup-timeout = 10 s

    # Timout after which the graceful shutdown of the remoting subsystem is
    # considered to be failed. After the timeout the remoting system is
    # forcefully shut down. Increase this value if your transport drivers
    # (see the enabled-transports section) need longer time to stop properly.
    shutdown-timeout = 10 s

    # Before shutting down the drivers, the remoting subsystem attempts to flush
    # all pending writes. This setting controls the maximum time the remoting is
    # willing to wait before moving on to shut down the drivers.
    flush-wait-on-shutdown = 2 s

    # Reuse inbound connections for outbound messages
    use-passive-connections = on

    # Controls the backoff interval after a refused write is reattempted.
    # (Transports may refuse writes if their internal buffer is full)
    backoff-interval = 5 ms

    # Acknowledgment timeout of management commands sent to the transport stack.
    command-ack-timeout = 30 s

    # The timeout for outbound associations to perform the handshake.
    # If the transport is akka.remote.netty.tcp or akka.remote.netty.ssl
    # the configured connection-timeout for the transport will be used instead.
    handshake-timeout = 15 s
    
    ### Security settings

    # Enable untrusted mode for full security of server managed actors, prevents
    # system messages to be send by clients, e.g. messages like &#39;Create&#39;,
    # &#39;Suspend&#39;, &#39;Resume&#39;, &#39;Terminate&#39;, &#39;Supervise&#39;, &#39;Link&#39; etc.
    untrusted-mode = off

    # When &#39;untrusted-mode=on&#39; inbound actor selections are by default discarded.
    # Actors with paths defined in this white list are granted permission to receive actor
    # selections messages.
    # E.g. trusted-selection-paths = [&quot;/user/receptionist&quot;, &quot;/user/namingService&quot;]
    trusted-selection-paths = []

    # Should the remote server require that its peers share the same
    # secure-cookie (defined in the &#39;remote&#39; section)? Secure cookies are passed
    # between during the initial handshake. Connections are refused if the initial
    # message contains a mismatching cookie or the cookie is missing.
    require-cookie = off

    # Deprecated since 2.4-M1
    secure-cookie = &quot;&quot;

    ### Logging

    # If this is &quot;on&quot;, Akka will log all inbound messages at DEBUG level,
    # if off then they are not logged
    log-received-messages = off

    # If this is &quot;on&quot;, Akka will log all outbound messages at DEBUG level,
    # if off then they are not logged
    log-sent-messages = off

    # Sets the log granularity level at which Akka logs remoting events. This setting
    # can take the values OFF, ERROR, WARNING, INFO, DEBUG, or ON. For compatibility
    # reasons the setting &quot;on&quot; will default to &quot;debug&quot; level. Please note that the effective
    # logging level is still determined by the global logging level of the actor system:
    # for example debug level remoting events will be only logged if the system
    # is running with debug level logging.
    # Failures to deserialize received messages also fall under this flag.
    log-remote-lifecycle-events = on

    # Logging of message types with payload size in bytes larger than
    # this value. Maximum detected size per message type is logged once,
    # with an increase threshold of 10%.
    # By default this feature is turned off. Activate it by setting the property to
    # a value in bytes, such as 1000b. Note that for all messages larger than this
    # limit there will be extra performance and scalability cost.
    log-frame-size-exceeding = off

    # Log warning if the number of messages in the backoff buffer in the endpoint
    # writer exceeds this limit. It can be disabled by setting the value to off.
    log-buffer-size-exceeding = 50000



    # After failed to establish an outbound connection, the remoting will mark the
    # address as failed. This configuration option controls how much time should
    # be elapsed before reattempting a new connection. While the address is
    # gated, all messages sent to the address are delivered to dead-letters.
    # Since this setting limits the rate of reconnects setting it to a
    # very short interval (i.e. less than a second) may result in a storm of
    # reconnect attempts.
    retry-gate-closed-for = 5 s

    # After catastrophic communication failures that result in the loss of system
    # messages or after the remote DeathWatch triggers the remote system gets
    # quarantined to prevent inconsistent behavior.
    # This setting controls how long the Quarantine marker will be kept around
    # before being removed to avoid long-term memory leaks.
    # WARNING: DO NOT change this to a small value to re-enable communication with
    # quarantined nodes. Such feature is not supported and any behavior between
    # the affected systems after lifting the quarantine is undefined.
    prune-quarantine-marker-after = 5 d

    # If system messages have been exchanged between two systems (i.e. remote death
    # watch or remote deployment has been used) a remote system will be marked as
    # quarantined after the two system has no active association, and no
    # communication happens during the time configured here.
    # The only purpose of this setting is to avoid storing system message redelivery
    # data (sequence number state, etc.) for an undefined amount of time leading to long
    # term memory leak. Instead, if a system has been gone for this period,
    # or more exactly
    # - there is no association between the two systems (TCP connection, if TCP transport is used)
    # - neither side has been attempting to communicate with the other
    # - there are no pending system messages to deliver
    # for the amount of time configured here, the remote system will be quarantined and all state
    # associated with it will be dropped.
    quarantine-after-silence = 5 d

    # This setting defines the maximum number of unacknowledged system messages
    # allowed for a remote system. If this limit is reached the remote system is
    # declared to be dead and its UID marked as tainted.
    system-message-buffer-size = 20000

    # This setting defines the maximum idle time after an individual
    # acknowledgement for system messages is sent. System message delivery
    # is guaranteed by explicit acknowledgement messages. These acks are
    # piggybacked on ordinary traffic messages. If no traffic is detected
    # during the time period configured here, the remoting will send out
    # an individual ack.
    system-message-ack-piggyback-timeout = 0.3 s

    # This setting defines the time after internal management signals
    # between actors (used for DeathWatch and supervision) that have not been
    # explicitly acknowledged or negatively acknowledged are resent.
    # Messages that were negatively acknowledged are always immediately
    # resent.
    resend-interval = 2 s

    # Maximum number of unacknowledged system messages that will be resent
    # each &#39;resend-interval&#39;. If you watch many (&gt; 1000) remote actors you can
    # increase this value to for example 600, but a too large limit (e.g. 10000)
    # may flood the connection and might cause false failure detection to trigger.
    # Test such a configuration by watching all actors at the same time and stop
    # all watched actors at the same time.
    resend-limit = 200

    # WARNING: this setting should not be not changed unless all of its consequences
    # are properly understood which assumes experience with remoting internals
    # or expert advice.
    # This setting defines the time after redelivery attempts of internal management
    # signals are stopped to a remote system that has been not confirmed to be alive by
    # this system before.
    initial-system-message-delivery-timeout = 3 m

    ### Transports and adapters

    # List of the transport drivers that will be loaded by the remoting.
    # A list of fully qualified config paths must be provided where
    # the given configuration path contains a transport-class key
    # pointing to an implementation class of the Transport interface.
    # If multiple transports are provided, the address of the first
    # one will be used as a default address.
    enabled-transports = [&quot;akka.remote.netty.tcp&quot;]

    # Transport drivers can be augmented with adapters by adding their
    # name to the applied-adapters setting in the configuration of a
    # transport. The available adapters should be configured in this
    # section by providing a name, and the fully qualified name of
    # their corresponding implementation. The class given here
    # must implement akka.akka.remote.transport.TransportAdapterProvider
    # and have public constructor without parameters.
    adapters {
      gremlin = &quot;akka.remote.transport.FailureInjectorProvider&quot;
      trttl = &quot;akka.remote.transport.ThrottlerProvider&quot;
    }

    ### Default configuration for the Netty based transport drivers

    netty.tcp {
      # The class given here must implement the akka.remote.transport.Transport
      # interface and offer a public constructor which takes two arguments:
      #  1) akka.actor.ExtendedActorSystem
      #  2) com.typesafe.config.Config
      transport-class = &quot;akka.remote.transport.netty.NettyTransport&quot;

      # Transport drivers can be augmented with adapters by adding their
      # name to the applied-adapters list. The last adapter in the
      # list is the adapter immediately above the driver, while
      # the first one is the top of the stack below the standard
      # Akka protocol
      applied-adapters = []

      transport-protocol = tcp

      # The default remote server port clients should connect to.
      # Default is 2552 (AKKA), use 0 if you want a random available port
      # This port needs to be unique for each actor system on the same machine.
      port = 2552

      # The hostname or ip clients should connect to.
      # InetAddress.getLocalHost.getHostAddress is used if empty
      hostname = &quot;&quot;

      # Use this setting to bind a network interface to a different port
      # than remoting protocol expects messages at. This may be used
      # when running akka nodes in a separated networks (under NATs or docker containers).
      # Use 0 if you want a random available port. Examples:
      #
      # akka.remote.netty.tcp.port = 2552
      # akka.remote.netty.tcp.bind-port = 2553
      # Network interface will be bound to the 2553 port, but remoting protocol will
      # expect messages sent to port 2552.
      #
      # akka.remote.netty.tcp.port = 0
      # akka.remote.netty.tcp.bind-port = 0
      # Network interface will be bound to a random port, and remoting protocol will
      # expect messages sent to the bound port.
      #
      # akka.remote.netty.tcp.port = 2552
      # akka.remote.netty.tcp.bind-port = 0
      # Network interface will be bound to a random port, but remoting protocol will
      # expect messages sent to port 2552.
      #
      # akka.remote.netty.tcp.port = 0
      # akka.remote.netty.tcp.bind-port = 2553
      # Network interface will be bound to the 2553 port, and remoting protocol will
      # expect messages sent to the bound port.
      #
      # akka.remote.netty.tcp.port = 2552
      # akka.remote.netty.tcp.bind-port = &quot;&quot;
      # Network interface will be bound to the 2552 port, and remoting protocol will
      # expect messages sent to the bound port.
      #
      # akka.remote.netty.tcp.port if empty
      bind-port = &quot;&quot;

      # Use this setting to bind a network interface to a different hostname or ip
      # than remoting protocol expects messages at.
      # Use &quot;0.0.0.0&quot; to bind to all interfaces.
      # akka.remote.netty.tcp.hostname if empty
      bind-hostname = &quot;&quot;

      # Enables SSL support on this transport
      enable-ssl = false

      # Sets the connectTimeoutMillis of all outbound connections,
      # i.e. how long a connect may take until it is timed out
      connection-timeout = 15 s

      # If set to &quot;&lt;id.of.dispatcher&gt;&quot; then the specified dispatcher
      # will be used to accept inbound connections, and perform IO. If &quot;&quot; then
      # dedicated threads will be used.
      # Please note that the Netty driver only uses this configuration and does
      # not read the &quot;akka.remote.use-dispatcher&quot; entry. Instead it has to be
      # configured manually to point to the same dispatcher if needed.
      use-dispatcher-for-io = &quot;&quot;

      # Sets the high water mark for the in and outbound sockets,
      # set to 0b for platform default
      write-buffer-high-water-mark = 0b

      # Sets the low water mark for the in and outbound sockets,
      # set to 0b for platform default
      write-buffer-low-water-mark = 0b

      # Sets the send buffer size of the Sockets,
      # set to 0b for platform default
      send-buffer-size = 256000b

      # Sets the receive buffer size of the Sockets,
      # set to 0b for platform default
      receive-buffer-size = 256000b

      # Maximum message size the transport will accept, but at least
      # 32000 bytes.
      # Please note that UDP does not support arbitrary large datagrams,
      # so this setting has to be chosen carefully when using UDP.
      # Both send-buffer-size and receive-buffer-size settings has to
      # be adjusted to be able to buffer messages of maximum size.
      maximum-frame-size = 128000b

      # Sets the size of the connection backlog
      backlog = 4096

      # Enables the TCP_NODELAY flag, i.e. disables Nagle’s algorithm
      tcp-nodelay = on

      # Enables TCP Keepalive, subject to the O/S kernel’s configuration
      tcp-keepalive = on

      # Enables SO_REUSEADDR, which determines when an ActorSystem can open
      # the specified listen port (the meaning differs between *nix and Windows)
      # Valid values are &quot;on&quot;, &quot;off&quot; and &quot;off-for-windows&quot;
      # due to the following Windows bug: http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=4476378
      # &quot;off-for-windows&quot; of course means that it&#39;s &quot;on&quot; for all other platforms
      tcp-reuse-addr = off-for-windows

      # Used to configure the number of I/O worker threads on server sockets
      server-socket-worker-pool {
        # Min number of threads to cap factor-based number to
        pool-size-min = 2

        # The pool size factor is used to determine thread pool size
        # using the following formula: ceil(available processors * factor).
        # Resulting size is then bounded by the pool-size-min and
        # pool-size-max values.
        pool-size-factor = 1.0

        # Max number of threads to cap factor-based number to
        pool-size-max = 2
      }

      # Used to configure the number of I/O worker threads on client sockets
      client-socket-worker-pool {
        # Min number of threads to cap factor-based number to
        pool-size-min = 2

        # The pool size factor is used to determine thread pool size
        # using the following formula: ceil(available processors * factor).
        # Resulting size is then bounded by the pool-size-min and
        # pool-size-max values.
        pool-size-factor = 1.0

        # Max number of threads to cap factor-based number to
        pool-size-max = 2
      }


    }

    netty.udp = ${akka.remote.netty.tcp}
    netty.udp {
      transport-protocol = udp
    }

    netty.ssl = ${akka.remote.netty.tcp}
    netty.ssl = {
      # Enable SSL/TLS encryption.
      # This must be enabled on both the client and server to work.
      enable-ssl = true

      security {
        # This is the Java Key Store used by the server connection
        key-store = &quot;keystore&quot;

        # This password is used for decrypting the key store
        key-store-password = &quot;changeme&quot;

        # This password is used for decrypting the key
        key-password = &quot;changeme&quot;

        # This is the Java Key Store used by the client connection
        trust-store = &quot;truststore&quot;

        # This password is used for decrypting the trust store
        trust-store-password = &quot;changeme&quot;

        # Protocol to use for SSL encryption, choose from:
        # TLS 1.2 is available since JDK7, and default since JDK8:
        # https://blogs.oracle.com/java-platform-group/entry/java_8_will_use_tls
        protocol = &quot;TLSv1.2&quot;

        # Example: [&quot;TLS_RSA_WITH_AES_128_CBC_SHA&quot;, &quot;TLS_RSA_WITH_AES_256_CBC_SHA&quot;]
        # You need to install the JCE Unlimited Strength Jurisdiction Policy
        # Files to use AES 256.
        # More info here:
        # http://docs.oracle.com/javase/7/docs/technotes/guides/security/SunProviders.html#SunJCEProvider
        enabled-algorithms = [&quot;TLS_RSA_WITH_AES_128_CBC_SHA&quot;]

        # There are three options, in increasing order of security:
        # &quot;&quot; or SecureRandom =&gt; (default)
        # &quot;SHA1PRNG&quot; =&gt; Can be slow because of blocking issues on Linux
        # &quot;AES128CounterSecureRNG&quot; =&gt; fastest startup and based on AES encryption
        # algorithm
        # &quot;AES256CounterSecureRNG&quot;
        #
        # The following are deprecated in Akka 2.4. They use one of 3 possible
        # seed sources, depending on availability: /dev/random, random.org and
        # SecureRandom (provided by Java)
        # &quot;AES128CounterInetRNG&quot;
        # &quot;AES256CounterInetRNG&quot; (Install JCE Unlimited Strength Jurisdiction
        # Policy Files first)
        # Setting a value here may require you to supply the appropriate cipher
        # suite (see enabled-algorithms section above)
        random-number-generator = &quot;&quot;
      }
    }

    ### Default configuration for the failure injector transport adapter

    gremlin {
      # Enable debug logging of the failure injector transport adapter
      debug = off
    }

    ### Default dispatcher for the remoting subsystem

    default-remote-dispatcher {
      type = Dispatcher
      executor = &quot;fork-join-executor&quot;
      fork-join-executor {
        parallelism-min = 2
        parallelism-factor = 0.5
        parallelism-max = 16
      }
      throughput = 10
    }

    backoff-remote-dispatcher {
      type = Dispatcher
      executor = &quot;fork-join-executor&quot;
      fork-join-executor {
        # Min number of threads to cap factor-based parallelism number to
        parallelism-min = 2
        parallelism-max = 2
      }
    }
  }
}
</pre></div>
</div>
</div>
<div class="section" id="akka-remote-artery">
<span id="config-akka-remote-artery"></span><h3>akka-remote (artery)</h3>
<div class="highlight-none"><div class="highlight"><pre>#####################################
# Akka Remote Reference Config File #
#####################################

# This is the reference config file that contains all the default settings.
# Make your edits/overrides in your application.conf.

# comments about akka.actor settings left out where they are already in akka-
# actor.jar, because otherwise they would be repeated in config rendering.
#
# For the configuration of the new remoting implementation (Artery) please look
# at the bottom section of this file as it is listed separately.

akka {

  actor {

    serializers {
      akka-containers = &quot;akka.remote.serialization.MessageContainerSerializer&quot;
      akka-misc = &quot;akka.remote.serialization.MiscMessageSerializer&quot;
      artery = &quot;akka.remote.serialization.ArteryMessageSerializer&quot;
      proto = &quot;akka.remote.serialization.ProtobufSerializer&quot;
      daemon-create = &quot;akka.remote.serialization.DaemonMsgCreateSerializer&quot;
      primitive-long = &quot;akka.remote.serialization.LongSerializer&quot;
      primitive-int = &quot;akka.remote.serialization.IntSerializer&quot;
      primitive-string = &quot;akka.remote.serialization.StringSerializer&quot;
      primitive-bytestring = &quot;akka.remote.serialization.ByteStringSerializer&quot;
      akka-system-msg = &quot;akka.remote.serialization.SystemMessageSerializer&quot;
    }

    serialization-bindings {
      &quot;akka.actor.ActorSelectionMessage&quot; = akka-containers

      &quot;akka.remote.DaemonMsgCreate&quot; = daemon-create

      &quot;akka.remote.artery.ArteryMessage&quot; = artery

      # Since akka.protobuf.Message does not extend Serializable but
      # GeneratedMessage does, need to use the more specific one here in order
      # to avoid ambiguity.
      &quot;akka.protobuf.GeneratedMessage&quot; = proto

      # Since com.google.protobuf.Message does not extend Serializable but
      # GeneratedMessage does, need to use the more specific one here in order
      # to avoid ambiguity.
      # This com.google.protobuf serialization binding is only used if the class can be loaded,
      # i.e. com.google.protobuf dependency has been added in the application project.
      &quot;com.google.protobuf.GeneratedMessage&quot; = proto
    }

    # For the purpose of preserving protocol backward compatibility these bindings are not
    # included by default. They can be enabled with enable-additional-serialization-bindings=on.
    # They are enabled by default if akka.remote.artery.enabled=on.
    additional-serialization-bindings {
      &quot;akka.actor.Identify&quot; = akka-misc
      &quot;akka.actor.ActorIdentity&quot; = akka-misc
      &quot;scala.Some&quot; = akka-misc
      &quot;scala.None$&quot; = akka-misc
      &quot;akka.actor.Status$Success&quot; = akka-misc
      &quot;akka.actor.Status$Failure&quot; = akka-misc
      &quot;akka.actor.ActorRef&quot; = akka-misc
      &quot;akka.actor.PoisonPill$&quot; = akka-misc
      &quot;akka.actor.Kill$&quot; = akka-misc
      &quot;akka.remote.RemoteWatcher$Heartbeat$&quot; = akka-misc
      &quot;akka.remote.RemoteWatcher$HeartbeatRsp&quot; = akka-misc
      &quot;akka.actor.ActorInitializationException&quot; = akka-misc

      &quot;akka.dispatch.sysmsg.SystemMessage&quot; = akka-system-msg

      &quot;java.lang.String&quot; = primitive-string
      &quot;akka.util.ByteString$ByteString1C&quot; = primitive-bytestring
      &quot;akka.util.ByteString$ByteString1&quot; = primitive-bytestring
      &quot;akka.util.ByteString$ByteStrings&quot; = primitive-bytestring
      &quot;java.lang.Long&quot; = primitive-long
      &quot;scala.Long&quot; = primitive-long
      &quot;java.lang.Integer&quot; = primitive-int
      &quot;scala.Int&quot; = primitive-int

      # Java Serializer is by default used for exceptions.
      # It&#39;s recommended that you implement custom serializer for exceptions that are
      # sent remotely, e.g. in akka.actor.Status.Failure for ask replies. You can add
      # binding to akka-misc (MiscMessageSerializerSpec) for the exceptions that have
      # a constructor with single message String or constructor with message String as
      # first parameter and cause Throwable as second parameter. Note that it&#39;s not
      # safe to add this binding for general exceptions such as IllegalArgumentException
      # because it may have a subclass without required constructor.
      &quot;java.lang.Throwable&quot; = java
      &quot;akka.actor.IllegalActorStateException&quot; = akka-misc
      &quot;akka.actor.ActorKilledException&quot; = akka-misc
      &quot;akka.actor.InvalidActorNameException&quot; = akka-misc
      &quot;akka.actor.InvalidMessageException&quot; = akka-misc
    }

    serialization-identifiers {
      &quot;akka.remote.serialization.ProtobufSerializer&quot; = 2
      &quot;akka.remote.serialization.DaemonMsgCreateSerializer&quot; = 3
      &quot;akka.remote.serialization.MessageContainerSerializer&quot; = 6
      &quot;akka.remote.serialization.MiscMessageSerializer&quot; = 16
      &quot;akka.remote.serialization.ArteryMessageSerializer&quot; = 17
      &quot;akka.remote.serialization.LongSerializer&quot; = 18
      &quot;akka.remote.serialization.IntSerializer&quot; = 19
      &quot;akka.remote.serialization.StringSerializer&quot; = 20
      &quot;akka.remote.serialization.ByteStringSerializer&quot; = 21
      &quot;akka.remote.serialization.SystemMessageSerializer&quot; = 22
    }

    deployment {

      default {

        # if this is set to a valid remote address, the named actor will be
        # deployed at that node e.g. &quot;akka.tcp://sys@host:port&quot;
        remote = &quot;&quot;

        target {

          # A list of hostnames and ports for instantiating the children of a
          # router
          #   The format should be on &quot;akka.tcp://sys@host:port&quot;, where:
          #    - sys is the remote actor system name
          #    - hostname can be either hostname or IP address the remote actor
          #      should connect to
          #    - port should be the port for the remote server on the other node
          # The number of actor instances to be spawned is still taken from the
          # nr-of-instances setting as for local routers; the instances will be
          # distributed round-robin among the given nodes.
          nodes = []

        }
      }
    }
  }

  remote {
    ### Settings shared by classic remoting and Artery (the new implementation of remoting)

    # If set to a nonempty string remoting will use the given dispatcher for
    # its internal actors otherwise the default dispatcher is used. Please note
    # that since remoting can load arbitrary 3rd party drivers (see
    # &quot;enabled-transport&quot; and &quot;adapters&quot; entries) it is not guaranteed that
    # every module will respect this setting.
    use-dispatcher = &quot;akka.remote.default-remote-dispatcher&quot;

    # Settings for the failure detector to monitor connections.
    # For TCP it is not important to have fast failure detection, since
    # most connection failures are captured by TCP itself.
    # The default DeadlineFailureDetector will trigger if there are no heartbeats within
    # the duration heartbeat-interval + acceptable-heartbeat-pause, i.e. 20 seconds
    # with the default settings.
    transport-failure-detector {

      # FQCN of the failure detector implementation.
      # It must implement akka.remote.FailureDetector and have
      # a public constructor with a com.typesafe.config.Config and
      # akka.actor.EventStream parameter.
      implementation-class = &quot;akka.remote.DeadlineFailureDetector&quot;

      # How often keep-alive heartbeat messages should be sent to each connection.
      heartbeat-interval = 4 s

      # Number of potentially lost/delayed heartbeats that will be
      # accepted before considering it to be an anomaly.
      # A margin to the `heartbeat-interval` is important to be able to survive sudden,
      # occasional, pauses in heartbeat arrivals, due to for example garbage collect or
      # network drop.
      acceptable-heartbeat-pause = 16 s
    }

    # Settings for the Phi accrual failure detector (http://www.jaist.ac.jp/~defago/files/pdf/IS_RR_2004_010.pdf
    # [Hayashibara et al]) used for remote death watch.
    # The default PhiAccrualFailureDetector will trigger if there are no heartbeats within
    # the duration heartbeat-interval + acceptable-heartbeat-pause + threshold_adjustment,
    # i.e. around 12.5 seconds with default settings.
    watch-failure-detector {

      # FQCN of the failure detector implementation.
      # It must implement akka.remote.FailureDetector and have
      # a public constructor with a com.typesafe.config.Config and
      # akka.actor.EventStream parameter.
      implementation-class = &quot;akka.remote.PhiAccrualFailureDetector&quot;

      # How often keep-alive heartbeat messages should be sent to each connection.
      heartbeat-interval = 1 s

      # Defines the failure detector threshold.
      # A low threshold is prone to generate many wrong suspicions but ensures
      # a quick detection in the event of a real crash. Conversely, a high
      # threshold generates fewer mistakes but needs more time to detect
      # actual crashes.
      threshold = 10.0

      # Number of the samples of inter-heartbeat arrival times to adaptively
      # calculate the failure timeout for connections.
      max-sample-size = 200

      # Minimum standard deviation to use for the normal distribution in
      # AccrualFailureDetector. Too low standard deviation might result in
      # too much sensitivity for sudden, but normal, deviations in heartbeat
      # inter arrival times.
      min-std-deviation = 100 ms

      # Number of potentially lost/delayed heartbeats that will be
      # accepted before considering it to be an anomaly.
      # This margin is important to be able to survive sudden, occasional,
      # pauses in heartbeat arrivals, due to for example garbage collect or
      # network drop.
      acceptable-heartbeat-pause = 10 s


      # How often to check for nodes marked as unreachable by the failure
      # detector
      unreachable-nodes-reaper-interval = 1s

      # After the heartbeat request has been sent the first failure detection
      # will start after this period, even though no heartbeat mesage has
      # been received.
      expected-response-after = 1 s

    }

    ### Configuration for Artery, the reimplementation of remoting
    artery {

      # Enable the new remoting with this flag
      enabled = off

      # Canonical address is the address other clients should connect to.
      # Artery transport will expect messages to this address.
      canonical {

        # The default remote server port clients should connect to.
        # Default is 25520, use 0 if you want a random available port
        # This port needs to be unique for each actor system on the same machine.
        port = 25520

        # Hostname clients should connect to. Can be set to an ip, hostname
        # or one of the following special values:
        #   &quot;&lt;getHostAddress&gt;&quot;   InetAddress.getLocalHost.getHostAddress
        #   &quot;&lt;getHostName&gt;&quot;      InetAddress.getLocalHost.getHostName
        #
        hostname = &quot;&lt;getHostAddress&gt;&quot;
      }

      # Use these settings to bind a network interface to a different address
      # than artery expects messages at. This may be used when running Akka
      # nodes in a separated networks (under NATs or in containers). If canonical
      # and bind addresses are different, then network configuration that relays
      # communications from canonical to bind addresses is expected.
      bind {

        # Port to bind a network interface to. Can be set to a port number
        # of one of the following special values:
        #   0    random available port
        #   &quot;&quot;   akka.remote.artery.canonical.port
        #
        port = &quot;&quot;

        # Hostname to bind a network interface to. Can be set to an ip, hostname
        # or one of the following special values:
        #   &quot;0.0.0.0&quot;            all interfaces
        #   &quot;&quot;                   akka.remote.artery.canonical.hostname
        #   &quot;&lt;getHostAddress&gt;&quot;   InetAddress.getLocalHost.getHostAddress
        #   &quot;&lt;getHostName&gt;&quot;      InetAddress.getLocalHost.getHostName
        #
        hostname = &quot;&quot;
      }

      # Actor paths to use the large message stream for when a message
      # is sent to them over remoting. The large message stream dedicated
      # is separate from &quot;normal&quot; and system messages so that sending a
      # large message does not interfere with them.
      # Entries should be the full path to the actor. Wildcards in the form of &quot;*&quot;
      # can be supplied at any place and matches any name at that segment -
      # &quot;/user/supervisor/actor/*&quot; will match any direct child to actor,
      # while &quot;/supervisor/*/child&quot; will match any grandchild to &quot;supervisor&quot; that
      # has the name &quot;child&quot;
      # Messages sent to ActorSelections will not be passed through the large message
      # stream, to pass such messages through the large message stream the selections
      # but must be resolved to ActorRefs first.
      large-message-destinations = []

      # Enable untrusted mode, which discards inbound system messages, PossiblyHarmful and
      # ActorSelection messages. E.g. remote watch and remote deployment will not work.
      # ActorSelection messages can be enabled for specific paths with the trusted-selection-paths
      untrusted-mode = off

      # When &#39;untrusted-mode=on&#39; inbound actor selections are by default discarded.
      # Actors with paths defined in this white list are granted permission to receive actor
      # selections messages.
      # E.g. trusted-selection-paths = [&quot;/user/receptionist&quot;, &quot;/user/namingService&quot;]
      trusted-selection-paths = []

      # If this is &quot;on&quot;, all inbound remote messages will be logged at DEBUG level,
      # if off then they are not logged
      log-received-messages = off

      # If this is &quot;on&quot;, all outbound remote messages will be logged at DEBUG level,
      # if off then they are not logged
      log-sent-messages = off

      advanced {

        # Maximum serialized message size, including header data.
        maximum-frame-size = 256 KiB

        # Direct byte buffers are reused in a pool with this maximum size.
        # Each buffer has the size of &#39;maximum-frame-size&#39;.
        # This is not a hard upper limit on number of created buffers. Additional
        # buffers will be created if needed, e.g. when using many outbound
        # associations at the same time. Such additional buffers will be garbage
        # collected, which is not as efficient as reusing buffers in the pool.
        buffer-pool-size = 128

        # Maximum serialized message size for the large messages, including header data.
        # See &#39;large-message-destinations&#39;.
        maximum-large-frame-size = 2 MiB

        # Direct byte buffers for the large messages are reused in a pool with this maximum size.
        # Each buffer has the size of &#39;maximum-large-frame-size&#39;.
        # See &#39;large-message-destinations&#39;.
        # This is not a hard upper limit on number of created buffers. Additional
        # buffers will be created if needed, e.g. when using many outbound
        # associations at the same time. Such additional buffers will be garbage
        # collected, which is not as efficient as reusing buffers in the pool.
        large-buffer-pool-size = 32

        # For enabling testing features, such as blackhole in akka-remote-testkit.
        test-mode = off

        # Settings for the materializer that is used for the remote streams.
        materializer = ${akka.stream.materializer}

        # If set to a nonempty string artery will use the given dispatcher for
        # the ordinary and large message streams, otherwise the default dispatcher is used.
        use-dispatcher = &quot;akka.remote.default-remote-dispatcher&quot;

        # If set to a nonempty string remoting will use the given dispatcher for
        # the control stream, otherwise the default dispatcher is used.
        # It can be good to not use the same dispatcher for the control stream as
        # the dispatcher for the ordinary message stream so that heartbeat messages
        # are not disturbed.
        use-control-stream-dispatcher = &quot;&quot;

        # Controls whether to start the Aeron media driver in the same JVM or use external
        # process. Set to &#39;off&#39; when using external media driver, and then also set the
        # &#39;aeron-dir&#39;.
        embedded-media-driver = on

        # Directory used by the Aeron media driver. It&#39;s mandatory to define the &#39;aeron-dir&#39;
        # if using external media driver, i.e. when &#39;embedded-media-driver = off&#39;.
        # Embedded media driver will use a this directory, or a temporary directory if this
        # property is not defined (empty).
        aeron-dir = &quot;&quot;

        # Whether to delete aeron embeded driver directory upon driver stop.
        delete-aeron-dir = yes

        # Level of CPU time used, on a scale between 1 and 10, during backoff/idle.
        # The tradeoff is that to have low latency more CPU time must be used to be
        # able to react quickly on incoming messages or send as fast as possible after
        # backoff backpressure.
        # Level 1 strongly prefer low CPU consumption over low latency.
        # Level 10 strongly prefer low latency over low CPU consumption.
        idle-cpu-level = 5

        # WARNING: This feature is not supported yet. Don&#39;t use other value than 1.
        # It requires more hardening and performance optimizations.
        # Number of outbound lanes for each outbound association. A value greater than 1
        # means that serialization can be performed in parallel for different destination
        # actors. The selection of lane is based on consistent hashing of the recipient
        # ActorRef to preserve message ordering per receiver.
        outbound-lanes = 1

        # WARNING: This feature is not supported yet. Don&#39;t use other value than 1.
        # It requires more hardening and performance optimizations.
        # Total number of inbound lanes, shared among all inbound associations. A value
        # greater than 1 means that deserialization can be performed in parallel for
        # different destination actors. The selection of lane is based on consistent
        # hashing of the recipient ActorRef to preserve message ordering per receiver.
        inbound-lanes = 1

        # Size of the send queue for outgoing messages. Messages will be dropped if
        # the queue becomes full. This may happen if you send a burst of many messages
        # without end-to-end flow control. Note that there is one such queue per
        # outbound association. The trade-off of using a larger queue size is that
        # it consumes more memory, since the queue is based on preallocated array with
        # fixed size.
        outbound-message-queue-size = 3072

        # Size of the send queue for outgoing control messages, such as system messages.
        # If this limit is reached the remote system is declared to be dead and its UID
        # marked as quarantined.
        # The trade-off of using a larger queue size is that it consumes more memory,
        # since the queue is based on preallocated array with fixed size.
        outbound-control-queue-size = 3072

        # Size of the send queue for outgoing large messages. Messages will be dropped if
        # the queue becomes full. This may happen if you send a burst of many messages
        # without end-to-end flow control. Note that there is one such queue per
        # outbound association. The trade-off of using a larger queue size is that
        # it consumes more memory, since the queue is based on preallocated array with
        # fixed size.
        outbound-large-message-queue-size = 256

        # This setting defines the maximum number of unacknowledged system messages
        # allowed for a remote system. If this limit is reached the remote system is
        # declared to be dead and its UID marked as quarantined.
        system-message-buffer-size = 20000

        # unacknowledged system messages are re-delivered with this interval
        system-message-resend-interval = 1 second

        # The timeout for outbound associations to perform the handshake.
        # This timeout must be greater than the &#39;image-liveness-timeout&#39;.
        handshake-timeout = 20 s

        # incomplete handshake attempt is retried with this interval
        handshake-retry-interval = 1 second

        # handshake requests are performed periodically with this interval,
        # also after the handshake has been completed to be able to establish
        # a new session with a restarted destination system
        inject-handshake-interval = 1 second

        # messages that are not accepted by Aeron are dropped after retrying for this period
        give-up-message-after = 60 seconds

        # System messages that are not acknowledged after re-sending for this period are
        # dropped and will trigger quarantine. The value should be longer than the length
        # of a network partition that you need to survive.
        give-up-system-message-after = 6 hours

        # during ActorSystem termination the remoting will wait this long for
        # an acknowledgment by the destination system that flushing of outstanding
        # remote messages has been completed
        shutdown-flush-timeout = 1 second

        # See &#39;inbound-max-restarts&#39;
        inbound-restart-timeout = 5 seconds

        # Max number of restarts within &#39;inbound-restart-timeout&#39; for the inbound streams.
        # If more restarts occurs the ActorSystem will be terminated.
        inbound-max-restarts = 5

        # See &#39;outbound-max-restarts&#39;
        outbound-restart-timeout = 5 seconds

        # Max number of restarts within &#39;outbound-restart-timeout&#39; for the outbound streams.
        # If more restarts occurs the ActorSystem will be terminated.
        outbound-max-restarts = 5

        # Stop outbound stream of a quarantined association after this idle timeout, i.e.
        # when not used any more.
        stop-quarantined-after-idle = 3 seconds

        # Timeout after which aeron driver has not had keepalive messages
        # from a client before it considers the client dead.
        client-liveness-timeout = 20 seconds

        # Timeout for each the INACTIVE and LINGER stages an aeron image
        # will be retained for when it is no longer referenced.
        # This timeout must be less than the &#39;handshake-timeout&#39;.
        image-liveness-timeout = 10 seconds

        # Timeout after which the aeron driver is considered dead
        # if it does not update its C&#39;n&#39;C timestamp.
        driver-timeout = 20 seconds

        flight-recorder {
          // FIXME it should be enabled by default when we have a good solution for naming the files
          enabled = off
          # Controls where the flight recorder file will be written. There are three options:
          # 1. Empty: a file will be generated in the temporary directory of the OS
          # 2. A relative or absolute path ending with &quot;.afr&quot;: this file will be used
          # 3. A relative or absolute path: this directory will be used, the file will get a random file name
          destination = &quot;&quot;
        }

        # compression of common strings in remoting messages, like actor destinations, serializers etc
        compression {

          actor-refs {
            # Max number of compressed actor-refs
            # Note that compression tables are &quot;rolling&quot; (i.e. a new table replaces the old
            # compression table once in a while), and this setting is only about the total number
            # of compressions within a single such table.
            # Must be a positive natural number.
            max = 256

            # interval between new table compression advertisements.
            # this means the time during which we collect heavy-hitter data and then turn it into a compression table.
            advertisement-interval = 1 minute # TODO find good number as default, for benchmarks trigger immediately
          }
          manifests {
            # Max number of compressed manifests
            # Note that compression tables are &quot;rolling&quot; (i.e. a new table replaces the old
            # compression table once in a while), and this setting is only about the total number
            # of compressions within a single such table.
            # Must be a positive natural number.
            max = 256

            # interval between new table compression advertisements.
            # this means the time during which we collect heavy-hitter data and then turn it into a compression table.
            advertisement-interval = 1 minute # TODO find good number as default, for benchmarks trigger immediately
          }
        }

        # List of fully qualified class names of remote instruments which should
        # be initialized and used for monitoring of remote messages.
        # The class must extend akka.remote.artery.RemoteInstrument and
        # have a public constructor with empty parameters or one ExtendedActorSystem
        # parameter.
        # A new instance of RemoteInstrument will be created for each encoder and decoder.
        # It&#39;s only called from the stage, so if it dosn&#39;t delegate to any shared instance
        # it doesn&#39;t have to be thread-safe.
        # Refer to `akka.remote.artery.RemoteInstrument` for more information.
        instruments = ${?akka.remote.artery.advanced.instruments} []
      }
    }
  }

}
</pre></div>
</div>
</div>
<div class="section" id="akka-testkit">
<span id="config-akka-testkit"></span><h3>akka-testkit</h3>
<div class="highlight-none"><div class="highlight"><pre>######################################
# Akka Testkit Reference Config File #
######################################

# This is the reference config file that contains all the default settings.
# Make your edits/overrides in your application.conf.

akka {
  test {
    # factor by which to scale timeouts during tests, e.g. to account for shared
    # build system load
    timefactor =  1.0

    # duration of EventFilter.intercept waits after the block is finished until
    # all required messages are received
    filter-leeway = 3s

    # duration to wait in expectMsg and friends outside of within() block
    # by default
    single-expect-default = 3s

    # The timeout that is added as an implicit by DefaultTimeout trait
    default-timeout = 5s

    calling-thread-dispatcher {
      type = akka.testkit.CallingThreadDispatcherConfigurator
    }
  }
  
  actor.serialization-bindings {
    &quot;akka.testkit.JavaSerializable&quot; = java
  }
}
</pre></div>
</div>
<p id="config-cluster-metrics">akka-cluster-metrics
~~~~~~~~~~~~--------</p>
<div class="highlight-none"><div class="highlight"><pre>##############################################
# Akka Cluster Metrics Reference Config File #
##############################################

# This is the reference config file that contains all the default settings.
# Make your edits in your application.conf in order to override these settings.

# Sigar provisioning:
#
#  User can provision sigar classes and native library in one of the following ways:
# 
#  1) Use https://github.com/kamon-io/sigar-loader Kamon sigar-loader as a project dependency for the user project.
#  Metrics extension will extract and load sigar library on demand with help of Kamon sigar provisioner.
# 
#  2) Use https://github.com/kamon-io/sigar-loader Kamon sigar-loader as java agent: `java -javaagent:/path/to/sigar-loader.jar`
#  Kamon sigar loader agent will extract and load sigar library during JVM start.
# 
#  3) Place `sigar.jar` on the `classpath` and sigar native library for the o/s on the `java.library.path`
#  User is required to manage both project dependency and library deployment manually.

# Cluster metrics extension.
# Provides periodic statistics collection and publication throughout the cluster.
akka.cluster.metrics {
    # Full path of dispatcher configuration key.
    # Use &quot;&quot; for default key `akka.actor.default-dispatcher`.
    dispatcher = &quot;&quot;
    # How long should any actor wait before starting the periodic tasks.
    periodic-tasks-initial-delay = 1s
    # Sigar native library extract location.
    # Use per-application-instance scoped location, such as program working directory.
    native-library-extract-folder = ${user.dir}&quot;/native&quot;
    # Metrics supervisor actor.
    supervisor {
        # Actor name. Example name space: /system/cluster-metrics
        name = &quot;cluster-metrics&quot;
        # Supervision strategy.
        strategy {
            #
            # FQCN of class providing `akka.actor.SupervisorStrategy`.
            # Must have a constructor with signature `&lt;init&gt;(com.typesafe.config.Config)`.
            # Default metrics strategy provider is a configurable extension of `OneForOneStrategy`.
            provider = &quot;akka.cluster.metrics.ClusterMetricsStrategy&quot;
            #
            # Configuration of the default strategy provider.
            # Replace with custom settings when overriding the provider.
            configuration = {
                # Log restart attempts.
                loggingEnabled = true
                # Child actor restart-on-failure window.
                withinTimeRange = 3s
                # Maximum number of restart attempts before child actor is stopped.
                maxNrOfRetries = 3
            }
        }
    }
    # Metrics collector actor.
    collector {
        # Enable or disable metrics collector for load-balancing nodes.
        # Metrics collection can also be controlled at runtime by sending control messages
        # to /system/cluster-metrics actor: `akka.cluster.metrics.{CollectionStartMessage,CollectionStopMessage}`
        enabled = on
        # FQCN of the metrics collector implementation.
        # It must implement `akka.cluster.metrics.MetricsCollector` and
        # have public constructor with akka.actor.ActorSystem parameter.
        # Will try to load in the following order of priority: 
        # 1) configured custom collector 2) internal `SigarMetricsCollector` 3) internal `JmxMetricsCollector`
        provider = &quot;&quot;
        # Try all 3 available collector providers, or else fail on the configured custom collector provider.
        fallback = true
        # How often metrics are sampled on a node.
        # Shorter interval will collect the metrics more often.
        # Also controls frequency of the metrics publication to the node system event bus. 
        sample-interval = 3s
        # How often a node publishes metrics information to the other nodes in the cluster.
        # Shorter interval will publish the metrics gossip more often.
        gossip-interval = 3s
        # How quickly the exponential weighting of past data is decayed compared to
        # new data. Set lower to increase the bias toward newer values.
        # The relevance of each data sample is halved for every passing half-life
        # duration, i.e. after 4 times the half-life, a data sample’s relevance is
        # reduced to 6% of its original relevance. The initial relevance of a data
        # sample is given by 1 – 0.5 ^ (collect-interval / half-life).
        # See http://en.wikipedia.org/wiki/Moving_average#Exponential_moving_average
        moving-average-half-life = 12s
    }
}

# Cluster metrics extension serializers and routers.
akka.actor {
    # Protobuf serializer for remote cluster metrics messages.
    serializers {
       akka-cluster-metrics = &quot;akka.cluster.metrics.protobuf.MessageSerializer&quot;
    }
    # Interface binding for remote cluster metrics messages.
    serialization-bindings {
       &quot;akka.cluster.metrics.ClusterMetricsMessage&quot; = akka-cluster-metrics
    }
    # Globally unique metrics extension serializer identifier.
    serialization-identifiers {
      &quot;akka.cluster.metrics.protobuf.MessageSerializer&quot; = 10
    }
    #  Provide routing of messages based on cluster metrics.
    router.type-mapping {
        cluster-metrics-adaptive-pool  = &quot;akka.cluster.metrics.AdaptiveLoadBalancingPool&quot;
        cluster-metrics-adaptive-group = &quot;akka.cluster.metrics.AdaptiveLoadBalancingGroup&quot;
    }
}
</pre></div>
</div>
<p id="config-cluster-tools">akka-cluster-tools
~~~~~~~~~~~~------</p>
<div class="highlight-none"><div class="highlight"><pre>############################################
# Akka Cluster Tools Reference Config File #
############################################

# This is the reference config file that contains all the default settings.
# Make your edits/overrides in your application.conf.

# //#pub-sub-ext-config
# Settings for the DistributedPubSub extension
akka.cluster.pub-sub {
  # Actor name of the mediator actor, /system/distributedPubSubMediator
  name = distributedPubSubMediator

  # Start the mediator on members tagged with this role.
  # All members are used if undefined or empty.
  role = &quot;&quot;

  # The routing logic to use for &#39;Send&#39;
  # Possible values: random, round-robin, broadcast
  routing-logic = random

  # How often the DistributedPubSubMediator should send out gossip information
  gossip-interval = 1s

  # Removed entries are pruned after this duration
  removed-time-to-live = 120s

  # Maximum number of elements to transfer in one message when synchronizing the registries.
  # Next chunk will be transferred in next round of gossip.
  max-delta-elements = 3000
  
  # The id of the dispatcher to use for DistributedPubSubMediator actors. 
  # If not specified default dispatcher is used.
  # If specified you need to define the settings of the actual dispatcher.
  use-dispatcher = &quot;&quot;
}
# //#pub-sub-ext-config

# Protobuf serializer for cluster DistributedPubSubMeditor messages
akka.actor {
  serializers {
    akka-pubsub = &quot;akka.cluster.pubsub.protobuf.DistributedPubSubMessageSerializer&quot;
  }
  serialization-bindings {
    &quot;akka.cluster.pubsub.DistributedPubSubMessage&quot; = akka-pubsub
  }
  serialization-identifiers {
    &quot;akka.cluster.pubsub.protobuf.DistributedPubSubMessageSerializer&quot; = 9
  }
}


# //#receptionist-ext-config
# Settings for the ClusterClientReceptionist extension
akka.cluster.client.receptionist {
  # Actor name of the ClusterReceptionist actor, /system/receptionist
  name = receptionist

  # Start the receptionist on members tagged with this role.
  # All members are used if undefined or empty.
  role = &quot;&quot;

  # The receptionist will send this number of contact points to the client
  number-of-contacts = 3

  # The actor that tunnel response messages to the client will be stopped
  # after this time of inactivity.
  response-tunnel-receive-timeout = 30s
  
  # The id of the dispatcher to use for ClusterReceptionist actors. 
  # If not specified default dispatcher is used.
  # If specified you need to define the settings of the actual dispatcher.
  use-dispatcher = &quot;&quot;

  # How often failure detection heartbeat messages should be received for
  # each ClusterClient
  heartbeat-interval = 2s

  # Number of potentially lost/delayed heartbeats that will be
  # accepted before considering it to be an anomaly.
  # The ClusterReceptionist is using the akka.remote.DeadlineFailureDetector, which
  # will trigger if there are no heartbeats within the duration
  # heartbeat-interval + acceptable-heartbeat-pause, i.e. 15 seconds with
  # the default settings.
  acceptable-heartbeat-pause = 13s

  # Failure detection checking interval for checking all ClusterClients
  failure-detection-interval = 2s
}
# //#receptionist-ext-config

# //#cluster-client-config
# Settings for the ClusterClient
akka.cluster.client {
  # Actor paths of the ClusterReceptionist actors on the servers (cluster nodes)
  # that the client will try to contact initially. It is mandatory to specify
  # at least one initial contact. 
  # Comma separated full actor paths defined by a string on the form of
  # &quot;akka.tcp://system@hostname:port/system/receptionist&quot;
  initial-contacts = []
  
  # Interval at which the client retries to establish contact with one of 
  # ClusterReceptionist on the servers (cluster nodes)
  establishing-get-contacts-interval = 3s
  
  # Interval at which the client will ask the ClusterReceptionist for
  # new contact points to be used for next reconnect.
  refresh-contacts-interval = 60s
  
  # How often failure detection heartbeat messages should be sent
  heartbeat-interval = 2s
  
  # Number of potentially lost/delayed heartbeats that will be
  # accepted before considering it to be an anomaly.
  # The ClusterClient is using the akka.remote.DeadlineFailureDetector, which
  # will trigger if there are no heartbeats within the duration 
  # heartbeat-interval + acceptable-heartbeat-pause, i.e. 15 seconds with
  # the default settings.
  acceptable-heartbeat-pause = 13s
  
  # If connection to the receptionist is not established the client will buffer
  # this number of messages and deliver them the connection is established.
  # When the buffer is full old messages will be dropped when new messages are sent
  # via the client. Use 0 to disable buffering, i.e. messages will be dropped
  # immediately if the location of the singleton is unknown.
  # Maximum allowed buffer size is 10000.
  buffer-size = 1000

  # If connection to the receiptionist is lost and the client has not been
  # able to acquire a new connection for this long the client will stop itself.
  # This duration makes it possible to watch the cluster client and react on a more permanent
  # loss of connection with the cluster, for example by accessing some kind of
  # service registry for an updated set of initial contacts to start a new cluster client with.
  # If this is not wanted it can be set to &quot;off&quot; to disable the timeout and retry
  # forever.
  reconnect-timeout = off
}
# //#cluster-client-config

# Protobuf serializer for ClusterClient messages
akka.actor {
  serializers {
    akka-cluster-client = &quot;akka.cluster.client.protobuf.ClusterClientMessageSerializer&quot;
  }
  serialization-bindings {
    &quot;akka.cluster.client.ClusterClientMessage&quot; = akka-cluster-client
  }
  serialization-identifiers {
    &quot;akka.cluster.client.protobuf.ClusterClientMessageSerializer&quot; = 15
  }
}

# //#singleton-config
akka.cluster.singleton {
  # The actor name of the child singleton actor.
  singleton-name = &quot;singleton&quot;
  
  # Singleton among the nodes tagged with specified role.
  # If the role is not specified it&#39;s a singleton among all nodes in the cluster.
  role = &quot;&quot;
  
  # When a node is becoming oldest it sends hand-over request to previous oldest, 
  # that might be leaving the cluster. This is retried with this interval until 
  # the previous oldest confirms that the hand over has started or the previous 
  # oldest member is removed from the cluster (+ akka.cluster.down-removal-margin).
  hand-over-retry-interval = 1s
  
  # The number of retries are derived from hand-over-retry-interval and
  # akka.cluster.down-removal-margin (or ClusterSingletonManagerSettings.removalMargin),
  # but it will never be less than this property.
  min-number-of-hand-over-retries = 10
}
# //#singleton-config

# //#singleton-proxy-config
akka.cluster.singleton-proxy {
  # The actor name of the singleton actor that is started by the ClusterSingletonManager
  singleton-name = ${akka.cluster.singleton.singleton-name}
  
  # The role of the cluster nodes where the singleton can be deployed. 
  # If the role is not specified then any node will do.
  role = &quot;&quot;
  
  # Interval at which the proxy will try to resolve the singleton instance.
  singleton-identification-interval = 1s
  
  # If the location of the singleton is unknown the proxy will buffer this
  # number of messages and deliver them when the singleton is identified. 
  # When the buffer is full old messages will be dropped when new messages are
  # sent via the proxy.
  # Use 0 to disable buffering, i.e. messages will be dropped immediately if
  # the location of the singleton is unknown.
  # Maximum allowed buffer size is 10000.
  buffer-size = 1000 
}
# //#singleton-proxy-config

# Serializer for cluster ClusterSingleton messages
akka.actor {
  serializers {
    akka-singleton = &quot;akka.cluster.singleton.protobuf.ClusterSingletonMessageSerializer&quot;
  }
  serialization-bindings {
    &quot;akka.cluster.singleton.ClusterSingletonMessage&quot; = akka-singleton
  }
  serialization-identifiers {
    &quot;akka.cluster.singleton.protobuf.ClusterSingletonMessageSerializer&quot; = 14
  }
}
</pre></div>
</div>
<p id="config-cluster-sharding">akka-cluster-sharding
~~~~~~~~~~~~---------</p>
<div class="highlight-none"><div class="highlight"><pre>###############################################
# Akka Cluster Sharding Reference Config File #
###############################################

# This is the reference config file that contains all the default settings.
# Make your edits/overrides in your application.conf.


# //#sharding-ext-config
# Settings for the ClusterShardingExtension
akka.cluster.sharding {

  # The extension creates a top level actor with this name in top level system scope,
  # e.g. &#39;/system/sharding&#39;
  guardian-name = sharding

  # Specifies that entities runs on cluster nodes with a specific role.
  # If the role is not specified (or empty) all nodes in the cluster are used.
  role = &quot;&quot;

  # When this is set to &#39;on&#39; the active entity actors will automatically be restarted
  # upon Shard restart. i.e. if the Shard is started on a different ShardRegion
  # due to rebalance or crash.
  remember-entities = off

  # If the coordinator can&#39;t store state changes it will be stopped
  # and started again after this duration, with an exponential back-off
  # of up to 5 times this duration.
  coordinator-failure-backoff = 5 s

  # The ShardRegion retries registration and shard location requests to the
  # ShardCoordinator with this interval if it does not reply.
  retry-interval = 2 s

  # Maximum number of messages that are buffered by a ShardRegion actor.
  buffer-size = 100000

  # Timeout of the shard rebalancing process.
  handoff-timeout = 60 s

  # Time given to a region to acknowledge it&#39;s hosting a shard.
  shard-start-timeout = 10 s

  # If the shard is remembering entities and can&#39;t store state changes
  # will be stopped and then started again after this duration. Any messages
  # sent to an affected entity may be lost in this process.
  shard-failure-backoff = 10 s

  # If the shard is remembering entities and an entity stops itself without
  # using passivate. The entity will be restarted after this duration or when
  # the next message for it is received, which ever occurs first.
  entity-restart-backoff = 10 s

  # Rebalance check is performed periodically with this interval.
  rebalance-interval = 10 s

  # Absolute path to the journal plugin configuration entity that is to be
  # used for the internal persistence of ClusterSharding. If not defined
  # the default journal plugin is used. Note that this is not related to
  # persistence used by the entity actors.
  journal-plugin-id = &quot;&quot;

  # Absolute path to the snapshot plugin configuration entity that is to be
  # used for the internal persistence of ClusterSharding. If not defined
  # the default snapshot plugin is used. Note that this is not related to
  # persistence used by the entity actors.
  snapshot-plugin-id = &quot;&quot;

  # Parameter which determines how the coordinator will be store a state
  # valid values either &quot;persistence&quot; or &quot;ddata&quot;
  # The &quot;ddata&quot; mode is experimental, since it depends on the experimental
  # module akka-distributed-data-experimental.
  state-store-mode = &quot;persistence&quot;

  # The shard saves persistent snapshots after this number of persistent
  # events. Snapshots are used to reduce recovery times.
  snapshot-after = 1000

  # Setting for the default shard allocation strategy
  least-shard-allocation-strategy {
    # Threshold of how large the difference between most and least number of
    # allocated shards must be to begin the rebalancing.
    rebalance-threshold = 10

    # The number of ongoing rebalancing processes is limited to this number.
    max-simultaneous-rebalance = 3
  }

  # Timeout of waiting the initial distributed state (an initial state will be queried again if the timeout happened)
  # works only for state-store-mode = &quot;ddata&quot;
  waiting-for-state-timeout = 5 s

  # Timeout of waiting for update the distributed state (update will be retried if the timeout happened)
  # works only for state-store-mode = &quot;ddata&quot;
  updating-state-timeout = 5 s

  # The shard uses this strategy to determines how to recover the underlying entity actors. The strategy is only used
  # by the persistent shard when rebalancing or restarting. The value can either be &quot;all&quot; or &quot;constant&quot;. The &quot;all&quot;
  # strategy start all the underlying entity actors at the same time. The constant strategy will start the underlying
  # entity actors at a fix rate. The default strategy &quot;all&quot;.
  entity-recovery-strategy = &quot;all&quot;

  # Default settings for the constant rate entity recovery strategy
  entity-recovery-constant-rate-strategy {
    # Sets the frequency at which a batch of entity actors is started.
    frequency = 100 ms
    # Sets the number of entity actors to be restart at a particular interval
    number-of-entities = 5
  }

  # Settings for the coordinator singleton. Same layout as akka.cluster.singleton.
  # The &quot;role&quot; of the singleton configuration is not used. The singleton role will
  # be the same as &quot;akka.cluster.sharding.role&quot;.
  coordinator-singleton = ${akka.cluster.singleton}

  # The id of the dispatcher to use for ClusterSharding actors.
  # If not specified default dispatcher is used.
  # If specified you need to define the settings of the actual dispatcher.
  # This dispatcher for the entity actors is defined by the user provided
  # Props, i.e. this dispatcher is not used for the entity actors.
  use-dispatcher = &quot;&quot;
}
# //#sharding-ext-config


# Protobuf serializer for Cluster Sharding messages
akka.actor {
  serializers {
    akka-sharding = &quot;akka.cluster.sharding.protobuf.ClusterShardingMessageSerializer&quot;
  }
  serialization-bindings {
    &quot;akka.cluster.sharding.ClusterShardingSerializable&quot; = akka-sharding
  }
  serialization-identifiers {
    &quot;akka.cluster.sharding.protobuf.ClusterShardingMessageSerializer&quot; = 13
  }
}
</pre></div>
</div>
<p id="config-distributed-data">akka-distributed-data
~~~~~~~~~~~~---------</p>
<div class="highlight-none"><div class="highlight"><pre>##############################################
# Akka Distributed DataReference Config File #
##############################################

# This is the reference config file that contains all the default settings.
# Make your edits/overrides in your application.conf.


#//#distributed-data
# Settings for the DistributedData extension
akka.cluster.distributed-data {
  # Actor name of the Replicator actor, /system/ddataReplicator
  name = ddataReplicator

  # Replicas are running on members tagged with this role.
  # All members are used if undefined or empty.
  role = &quot;&quot;

  # How often the Replicator should send out gossip information
  gossip-interval = 2 s

  # How often the subscribers will be notified of changes, if any
  notify-subscribers-interval = 500 ms

  # Maximum number of entries to transfer in one gossip message when synchronizing
  # the replicas. Next chunk will be transferred in next round of gossip.
  max-delta-elements = 1000
  
  # The id of the dispatcher to use for Replicator actors. If not specified
  # default dispatcher is used.
  # If specified you need to define the settings of the actual dispatcher.
  use-dispatcher = &quot;&quot;

  # How often the Replicator checks for pruning of data associated with
  # removed cluster nodes.
  pruning-interval = 30 s
  
  # How long time it takes (worst case) to spread the data to all other replica nodes.
  # This is used when initiating and completing the pruning process of data associated
  # with removed cluster nodes. The time measurement is stopped when any replica is 
  # unreachable, so it should be configured to worst case in a healthy cluster.
  max-pruning-dissemination = 60 s
  
  # Serialized Write and Read messages are cached when they are sent to 
  # several nodes. If no further activity they are removed from the cache
  # after this duration.
  serializer-cache-time-to-live = 10s
  
}
#//#distributed-data

# Protobuf serializer for cluster DistributedData messages
akka.actor {
  serializers {
    akka-data-replication = &quot;akka.cluster.ddata.protobuf.ReplicatorMessageSerializer&quot;
    akka-replicated-data = &quot;akka.cluster.ddata.protobuf.ReplicatedDataSerializer&quot;
  }
  serialization-bindings {
    &quot;akka.cluster.ddata.Replicator$ReplicatorMessage&quot; = akka-data-replication
    &quot;akka.cluster.ddata.ReplicatedDataSerialization&quot; = akka-replicated-data
  }
  serialization-identifiers {
    &quot;akka.cluster.ddata.protobuf.ReplicatedDataSerializer&quot; = 11
    &quot;akka.cluster.ddata.protobuf.ReplicatorMessageSerializer&quot; = 12
  }
}
</pre></div>
</div>
</div>
</div>
</div>


          </div>
          <div class="span3"><p class="contents-title">Contents</p>
              <div id="scroller-anchor">
                <div id="scroller">
                  <div id="toc"></div>
                </div>
              </div></div>
        </div>
      </div>
    </div>
  </div>
  <div class="footer">
  <div class="container">
    <ul>
      <li><h5>Akka</h5></li>
      <li><a href="http://akka.io/docs">Documentation</a></li>
      <li><a href="http://doc.akka.io/docs/akka/current/additional/faq.html">FAQ</a></li>
      <li><a href="http://akka.io/downloads">Downloads</a></li>
      <li><a href="http://akka.io/news">News</a></li>
      <li><a href="http://letitcrash.com">Blog</a></li>
    </ul>
    <ul>
      <li><h5>Contribute</h5></li>
      <li><a href="http://akka.io/community">Community Projects</a></li>
      <li><a href="http://github.com/akka/akka">Source Code</a></li>
      <li><a href="http://groups.google.com/group/akka-user">Mailing List</a></li>
      <li><a href="http://doc.akka.io/docs/akka/current/project/issue-tracking.html">Report a Bug</a></li>
    </ul>
    <ul>
      <li><h5>Company</h5></li>
      <li><a href="http://www.lightbend.com/how/subscription">Commercial Support</a></li>
      <li><a href="http://akka.io/team">Team</a></li>
      <li><a href="mailto:info@lightbend.com">Contact</a></li>
    </ul>
    <ul>
      <li><img src="../_static/akka_icon_reverse.svg" align="center"/></li>
    </ul>
  </div>
  <div class="container copyright">
    <p style="float: left;">
      © 2015 <a href="http://www.lightbend.com/">Lightbend Inc.</a> <span class="license">Akka is Open Source and available under the Apache 2 License.</span>
    </p>
    <p style="float: right; font-size: 12px;">
      Last updated: Sep 30, 2016
    </p>
  </div>
</div>
<script type="text/javascript">
  var $toc = $('#toc');
  $toc.toc();

  // show clickable section sign when section header hovered:
  $('.section h2,.section h3,.section h4,.section h5').each(function(i, el) {
      var $el = $(el);
      $el.prepend($("<a class='section-marker' href='#" + $el.attr("id") + "'>&sect;</a>"))
  });
</script>

<!-- Algolia docs search -->
<script type="text/javascript">
  var version = DOCUMENTATION_OPTIONS.VERSION;

  var lang = "scala";
  var path = window.location.pathname;
  if (path.includes("/java/") || path.includes("java.html")) lang = "java";

  console.log("Search configured for:", lang, "@", version);

  docsearch({
    apiKey: '543bad5ad786495d9ccd445ed34ed082',
    indexName: 'akka_io',
    inputSelector: '#search',
    algoliaOptions: {
      hitsPerPage: 5,
      facetFilters: '[' + '["language:' + lang + '","language:general"]' + ',"version:' + version + '"]'
    }
  });

  // set up "/" as global shortcut for focusing on search
  $(document).keypress(function (event) {
    if (event.keyCode == 47) {
      $("#q").focus();
      return false; // swallow key event, otherwise the / char would be input into the search box
    }
  });
</script>

  

  </body>
</html>